{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "257c1153",
   "metadata": {},
   "source": [
    "## Model Selection and Parameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf6a12",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate how the NVIDIA NeMo Agent toolkit (NAT) optimizer can be used to create a robust model evaluation, comparison, and selection pipeline for custom datasets.\n",
    "\n",
    "**Goal**: exemplify the minimal configuration and demonstrate a practical example using the NAT optimizer module to evaluate and compare the performance of various LLMs. Help NAT users establish a working understanding of this feature so that they can create similar workflows in their own institutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ee544",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    " \n",
    "- [0.0) Setup](#setup)\n",
    "  - [0.1) Prerequisites](#prereqs)\n",
    "  - [0.2) API Keys](#api-keys)\n",
    "  - [0.3) Installing NeMo Agent Toolkit](#install-nat)\n",
    "  - [0.4) Additional dependencies](#deps)\n",
    "- [1.0) LLM-as-a-judge with NAT](#llm-judge-h1)\n",
    "  - [1.1) Create a new workflow](#new-workflow)\n",
    "  - [1.2) Head-to-head comparison of multiple LLMs using eval](#nat-eval)\n",
    "    - [1.2.1) LLM-as-a-judge workflow config](#config)\n",
    "    - [1.2.2) Add optimizer settings to the configuration](#optimizer-settings)\n",
    "    - [1.2.3) Create an eval dataset](#dataset)\n",
    "    - [1.2.4) Run the optimizer](#optimize-first)\n",
    "    - [1.2.5) Interpret first optimizer run](#interpret-optimizer-first)\n",
    "- [2.0) Optimized model and parameter selection for tool-calling agents](#optimize-tool-calling-agents)\n",
    "  - [2.1) Create a tool-calling agent](#create-triage-agent)\n",
    "  - [2.2) Configure the tool-calling agent](#configure-triage-agent)\n",
    "  - [2.3) Test the tool-calling agent](#test-triage-agent)\n",
    "  - [2.4) Evaluate the tool-calling agent](#eval-triage-agent1)\n",
    "  - [2.5) Optimize the tool-calling agent's LLM](#optimize-triage-agent)\n",
    "  - [2.6) Re-evaluate the optimized tool-calling agent](#eval-triage-agent2)\n",
    "- [3.0) Concurrent model parameter and prompt tuning](#model-and-prompt-tuning)\n",
    "  - [3.1) Optimizer configuration for all parameters (models, hyperparameters, and prompts)](#all-tuning-config)\n",
    "  - [3.2) Evaluate the agent](#all-tuning-initial-eval)\n",
    "  - [3.3) Optimize the agent](#all-tuning-optimize)\n",
    "  - [3.4) Re-evaluate the optimized tool-calling agent](#eval-triage-agent2)\n",
    "- [4.0) Next steps](#next-steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46297fd",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "# 0.0) Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8421ac5",
   "metadata": {},
   "source": [
    "<a id=\"prereqs\"></a>\n",
    "## 0.1) Prerequisites\n",
    "\n",
    "We strongly recommend that users begin this notebook with a working understanding of NAT workflows. Please refer to earlier iterations of this notebook series prior to beginning this notebook.\n",
    "\n",
    "- **Platform:** Linux, macOS, or Windows\n",
    "- **Python:** version 3.11, 3.12, or 3.13\n",
    "- **Python Packages:** `pip`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a4ad7",
   "metadata": {},
   "source": [
    "<a id=\"api-keys\"></a>\n",
    "## 0.2) API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b790034",
   "metadata": {},
   "source": [
    "For this notebook, you will need the following API keys to run all examples end-to-end:\n",
    "\n",
    "- **NVIDIA Build:** You can obtain an NVIDIA Build API Key by creating an [NVIDIA Build](https://build.nvidia.com) account and generating a key at https://build.nvidia.com/settings/api-keys\n",
    "\n",
    "Then you can run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4ff151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"NVIDIA_API_KEY\" not in os.environ:\n",
    "    nvidia_api_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvidia_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d98208",
   "metadata": {},
   "source": [
    "<a id=\"install-nat\"></a>\n",
    "## 0.3) Installing NeMo Agent Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6b321",
   "metadata": {},
   "source": [
    "The recommended way to install NAT is through `pip` or `uv pip`.\n",
    "\n",
    "First, we will install `uv` which offers parallel downloads and faster dependency resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8855c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1109b11",
   "metadata": {},
   "source": [
    "NeMo Agent toolkit can be installed through the PyPI `nvidia-nat` package.\n",
    "\n",
    "There are several optional subpackages available for NAT. For this example, we will rely on three subpackages:\n",
    "* The `nvidia-nat[langchain]` subpackage contains components for integrating with [LangChain](https://python.langchain.com/docs/introduction/).\n",
    "* The `nvidia-nat[profiling]` subpackage contains components for profiling and performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc18e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install \"nvidia-nat[langchain,profiling]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a34464",
   "metadata": {},
   "source": [
    "<a id=\"deps\"></a>\n",
    "## 0.4) Additional dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d73082df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.11 environment at: /Users/bbednarski/.venvs/unew_312\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 287ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# needed for the alert triage agent used later\n",
    "!uv pip install ansible-runner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71e5cc",
   "metadata": {},
   "source": [
    "<div style=\"color: red; font-style: italic;\">\n",
    "<strong>Note:</strong> Uncomment and run this cell to install git-lfs if using Google Colab.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d95af680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get update\n",
    "# !apt-get install git git-lfs -y\n",
    "# !git lfs install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3615a",
   "metadata": {},
   "source": [
    "<a id=\"llm-judge-h1\"></a>\n",
    "# 1.0) LLM-as-a-judge with NAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db2f3a",
   "metadata": {},
   "source": [
    "The `nat eval` and `nat optimize` utilities enable developers to easily integrate LLM-as-a-judge capabilities with their workflows. `nat eval` allows for simple evaluations of a NAT workflow against an eval dataset. `nat optimize` extends this functionality by integrating with the **Optuna** library to perform grid and stochastic parameter sweeps and evaluations to identify optimal configurations for a task.\n",
    "\n",
    "**Note:** _In this notebook, we will primarily demonstrate how to use `nat optimize` to identify a potentially optimal set of parameters for a NAT workflow. It is assumed that users will already have a strong understanding of ML model evaluations before building this concept into their workflows - as we will not be covering cross validation and train, validation, and test splitting of datasets. Please refer to python's [SciKit-Learn](https://scikit-learn.org/stable/) package as a strong reference for these concepts._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5114d358",
   "metadata": {},
   "source": [
    "<a id=\"new-workflow\"></a>\n",
    "## 1.1) Create a new workflow\n",
    "\n",
    "Create a basic chat completions workflow (using LangChain chat completions on backend)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e94f46ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing workflow 'tmp_workflow'...\n",
      "Workflow 'tmp_workflow' installed successfully.\n",
      "Workflow 'tmp_workflow' created successfully in '/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/notebooks/tmp_workflow'.\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!nat workflow create tmp_workflow --description \"A simple chat completion workflow to compare model performance\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c757d63",
   "metadata": {},
   "source": [
    "Let's look at the default configuration of this agent and confirm the agent type, LLMs, tool calls, and functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f53d5365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./tmp_workflow/configs/config_a.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tmp_workflow/configs/config_a.yml\n",
    "llms:\n",
    "  nim_llm:\n",
    "    _type: nim\n",
    "    model_name: meta/llama-3.1-8b-instruct\n",
    "    temperature: 0.7\n",
    "    max_tokens: 1024\n",
    "\n",
    "workflow:\n",
    "  _type: chat_completion  # Use the type directly\n",
    "  system_prompt: |\n",
    "    You are a helpful AI assistant. Provide clear, accurate, and helpful \n",
    "    responses to user queries. Be concise and informative.\n",
    "  llm_name: nim_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a0afc",
   "metadata": {},
   "source": [
    "Now let's run this workflow for a simple Q&A example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6510270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-24 10:24:04 - INFO     - nat.cli.commands.start:192 - Starting NAT from config file: 'tmp_workflow/configs/config_a.yml'\n",
      "2025-10-24 10:24:04 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "Configuration Summary:\n",
      "--------------------\n",
      "Workflow Type: chat_completion\n",
      "Number of Functions: 0\n",
      "Number of Function Groups: 0\n",
      "Number of LLMs: 1\n",
      "Number of Embedders: 0\n",
      "Number of Memory: 0\n",
      "Number of Object Stores: 0\n",
      "Number of Retrievers: 0\n",
      "Number of TTC Strategies: 0\n",
      "Number of Authentication Providers: 0\n",
      "\n",
      "2025-10-24 10:24:07 - INFO     - nat.front_ends.console.console_front_end_plugin:102 - --------------------------------------------------\n",
      "\u001b[32mWorkflow Result:\n",
      "[\"I'd be happy to help you choose a name for your new dog.\\n\\nHere are some popular and unique name suggestions for a dog:\\n\\nFor a male dog:\\n- Max\\n- Cooper\\n- Rocky\\n- Bear\\n- Finn\\n\\nFor a female dog:\\n- Luna\\n- Daisy\\n- Bella\\n- Lucy\\n- Ginger\\n\\nOr, if you'd like something more unique:\\n- Sage\\n- Wren\\n- Indie\\n- Clio\\n- Remi\\n\\nWhat breed or type of dog do you have? I can give more tailored suggestions!\"]\u001b[39m\n",
      "--------------------------------------------------\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!nat run --config_file tmp_workflow/configs/config_a.yml --input \"Suggest a single name for my new dog\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a740010",
   "metadata": {},
   "source": [
    "<a id=\"nat-eval\"></a>\n",
    "## 1.2) Head-to-head comparison of multiple LLMs using eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba364eb",
   "metadata": {},
   "source": [
    "Now that we've made a new workflow and shown that it works for a cursory `nat run` example, we will begin to build out an LLM-as-a-judge evaluation with trace profiling enabled for additional observability. In this next section, we are going to update the workflow configuration for evaluation and profiling.\n",
    "\n",
    "Step-by-step instructions can be found in [4_observability_evaluation_and_profiling.ipynb](./4_observability_evaluation_and_profiling.ipynb). An end-to-end example of using the Optimizer can be viewed in the [Email Phishing Analyzer](https://github.com/NVIDIA/NeMo-Agent-Toolkit/blob/develop/examples/evaluation_and_profiling/email_phishing_analyzer/src/nat_email_phishing_analyzer/configs/config_optimizer.yml).\n",
    "\n",
    "The profiler instruments and measures your workflow's performance, while evaluators judge the quality of the outputs. They're separate concepts, so they belong in different sections of the config!\n",
    "\n",
    "In this next step we will combine the eval and profile configuration into a single config for brevity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222012b",
   "metadata": {},
   "source": [
    "<a id=\"config\"></a>\n",
    "### 1.2.1) LLM-as-a-judge workflow config\n",
    "\n",
    "In the cell below we edit our initial workflow configuration to include `eval` and `optimizer` configurations.\n",
    "\n",
    "Key components of this configuration:\n",
    "\n",
    "**LLM Configuration:**\n",
    "- `chat_completion_llm`: The backbone LLM that powers the workflow\n",
    "- `optimizable_params`: Specifies which parameters the optimizer can tune (model name, temperature)\n",
    "- `search_space`: Defines the values the optimizer will explore during optimization\n",
    "\n",
    "**Judge LLM:**\n",
    "- `nim_judge_llm`: A separate, more capable LLM (meta/llama-3.1-405b-instruct) used by the evaluator to assess the quality of the workflow's outputs\n",
    "  - This LLM acts as an \"LLM-as-a-judge\" to score responses\n",
    "\n",
    "**Evaluation Components:**\n",
    "- `evaluators`: Define metrics to measure workflow quality (for example, accuracy, relevance)\n",
    "- `profiler`: Instruments the workflow to collect performance metrics (latency, token usage, costs)\n",
    "\n",
    "**Optimizer Components:**\n",
    "- `reps_per_param_set`: Number of times to evaluate each parameter combination for statistical reliability\n",
    "- `grid_search`: Strategy for exploring the search space (tests all combinations)\n",
    "- `eval_metrics`: Metrics used to guide optimization decisions (for example, maximize accuracy while minimizing cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f354066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tmp_workflow/configs/config_b.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile tmp_workflow/configs/config_b.yml\n",
    "llms:\n",
    "  chat_completion_llm:\n",
    "    _type: nim\n",
    "    model_name: meta/llama-3.1-8b-instruct\n",
    "    temperature: 0.0\n",
    "    max_tokens: 1024\n",
    "    optimizable_params:\n",
    "      - model_name\n",
    "      - temperature\n",
    "    search_space:\n",
    "      model_name:\n",
    "        values:\n",
    "          - meta/llama-3.1-8b-instruct\n",
    "          - meta/llama-3.1-70b-instruct\n",
    "      temperature:\n",
    "        values:\n",
    "          - 0.0\n",
    "          - 0.7\n",
    "\n",
    "  # Judge LLM for accuracy evaluation\n",
    "  nim_judge_llm:\n",
    "    _type: nim\n",
    "    model_name: meta/llama-3.1-405b-instruct\n",
    "    temperature: 0.0\n",
    "    max_tokens: 8  # RAGAS accuracy only needs a score (0-1)\n",
    "\n",
    "workflow:\n",
    "  _type: chat_completion\n",
    "  system_prompt: |\n",
    "    You are a helpful AI assistant. Provide clear, accurate, and helpful \n",
    "    responses to user queries. Be concise and informative.\n",
    "  llm_name: chat_completion_llm\n",
    "\n",
    "general:\n",
    "  telemetry:\n",
    "    logging:\n",
    "      console:\n",
    "        _type: console\n",
    "        level: INFO\n",
    "\n",
    "eval:\n",
    "  general:\n",
    "    output_dir: ./tmp_workflow/eval_output\n",
    "    verbose: true\n",
    "    dataset:\n",
    "        _type: json\n",
    "        file_path: ./tmp_workflow/data/eval_data.json\n",
    "\n",
    "  evaluators:\n",
    "    answer_accuracy:\n",
    "      _type: ragas\n",
    "      metric: AnswerAccuracy\n",
    "      llm_name: nim_judge_llm\n",
    "    llm_latency:\n",
    "      _type: avg_llm_latency\n",
    "    token_efficiency:\n",
    "      _type: avg_tokens_per_llm_end\n",
    "\n",
    "  profiler:\n",
    "      token_uniqueness_forecast: true\n",
    "      workflow_runtime_forecast: true\n",
    "      compute_llm_metrics: true\n",
    "      csv_exclude_io_text: true\n",
    "      prompt_caching_prefixes:\n",
    "        enable: true\n",
    "        min_frequency: 0.1\n",
    "      bottleneck_analysis:\n",
    "        enable_nested_stack: true\n",
    "      concurrency_spike_analysis:\n",
    "        enable: true\n",
    "        spike_threshold: 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e04758",
   "metadata": {},
   "source": [
    "<a id=\"optimizer-settings\"></a>\n",
    "### 1.2.2) Add optimizer settings to the configuration\n",
    "\n",
    "**For a complete reference of all optimizer configuration parameters, see the [Optimizer documentation](../../docs/source/reference/optimizer.md) or go to your working branch on [Github - dev](https://github.com/NVIDIA/NeMo-Agent-Toolkit/blob/develop/docs/source/reference/optimizer.md).**\n",
    "\n",
    "\n",
    "\n",
    "Next, we will append the optimizer-specific settings to our configuration file under the \"optimizer\" section. The following describes the purpose and configurability of each.\n",
    "\n",
    "**Top-Level Settings**\n",
    "\n",
    "`output_path: ./tmp_workflow/eval_output/optimizer/` - Specifies where all optimization results will be saved\n",
    "\n",
    "Files created here:\n",
    "- `optimized_config.yml` - The best configuration found\n",
    "- `trials_dataframe_params.csv` - Detailed results from all trials\n",
    "- `config_numeric_trial_{N}.yml` - Individual trial configurations\n",
    "- `plots/` - Pareto front visualizations (if multiple metrics)\n",
    "\n",
    "`reps_per_param_set: 10`\n",
    "\n",
    "> What it does: Number of times to run your workflow with each parameter configuration. This is important because LLMs are > non-deterministic (same input can give different outputs) and we often want to determine performance over a larger sample.\n",
    "> \n",
    "> How it works:\n",
    "> - If testing 5 different configurations × 10 reps = 50 total workflow runs\n",
    "> - Results are averaged across the 10 runs for statistical reliability\n",
    "> \n",
    "> Trade-off:\n",
    "> - Higher reps = more reliable results but slower optimization and more compute ysed\n",
    "> - Lower reps = faster but less confidence in which config is truly better, cheaper\n",
    "\n",
    "**Evaluation Metrics (`eval_metrics`)**\n",
    "\n",
    "This section defines what you're optimizing for. You can have multiple objectives.\n",
    "\n",
    "- `accuracy` (custom name, you choose this)\n",
    "- `token_efficiency` (another custom name)\n",
    "- `latency` (another custom name)\n",
    "\n",
    "Key Concepts:\n",
    "- `evaluator_name`: References an evaluator you've defined elsewhere in your config (must match exactly)\n",
    "- `direction`:\n",
    "  - `maximize` - Higher scores are better (accuracy, precision, F1)\n",
    "  - `minimize` - Lower scores are better (latency, cost, error rate)\n",
    "- Multi-objective optimization: With 3 metrics here, the optimizer finds configs that balance all three goals (Pareto optimization)\n",
    "  - `weight` - coefficient of relative importance for the optimizer (defaults to 1.0)\n",
    "\n",
    "**Numeric Optimization (`numeric`)**\n",
    "\n",
    "Controls how numeric/categorical parameters are optimized (uses Optuna library).\n",
    "\n",
    "`enabled: true`\n",
    "\n",
    "> What it does: Turns on optimization of numeric parameters (like `temperature`, `max_tokens`, model selection)\n",
    "> \n",
    "> When to enable: When you have optimizable parameters marked with `OptimizableField()` in your config\n",
    "> \n",
    "> When to disable: If you only want to optimize prompts, or run a single evaluation\n",
    "\n",
    "`sampler: grid`\n",
    "\n",
    "> What it does: Determines the search strategy for finding the best parameters\n",
    "> \n",
    "> Options:\n",
    "> - `grid` - Exhaustive search: Tests every combination of parameter values\n",
    ">   - Use when: Small search space, want guaranteed best result\n",
    ">   - Example: 3 models × 2 temperatures = 6 combinations\n",
    "> - `bayesian` or `null` - Smart search: Uses Bayesian optimization to intelligently sample promising areas\n",
    ">   - Use when: Large search space, limited time/budget\n",
    ">   - Example: Continuous ranges like temperature 0.0-1.0\n",
    "> \n",
    "> Must specify either:\n",
    "> - Explicit values: `[0.5, 0.7, 0.9]`, OR\n",
    "> - Range with step: `low: 0.0, high: 1.0, step: 0.1`\n",
    "\n",
    "**Prompt Optimization (`prompt`)**\n",
    "\n",
    "Controls genetic algorithm-based prompt optimization.\n",
    "\n",
    "`enabled: false`\n",
    "\n",
    "> What it does: Turns on/off LLM-based prompt evolution\n",
    "> \n",
    "> When to enable: When you want to optimize the actual text of prompts (like system prompts)\n",
    "> \n",
    "> When to disable:\n",
    "> - Comparing models and numeric parameters only (like this example)\n",
    "> - Don't have prompt parameters marked for optimization\n",
    "> - Want faster results (prompt optimization is slower)\n",
    "> \n",
    "> Requires:\n",
    "> - Prompt parameters marked with `OptimizableField(space=SearchSpace(is_prompt=True))`\n",
    "> - LLM functions for generating prompt variations\n",
    "\n",
    "**How This Configuration Works Together**\n",
    "\n",
    "With this specific config, here's what happens:\n",
    "\n",
    "Optimizer will:\n",
    "- Test different parameter combinations (models, settings, etc.)\n",
    "- Run each combination 10 times for reliability\n",
    "- Measure 3 things: accuracy (↑), token efficiency (↓), latency (↓)\n",
    "- Use grid search to test every combination systematically\n",
    "- Skip prompt optimization (only testing model/parameter combinations)\n",
    "\n",
    "Example workflow (if testing 3 models × 2 temperatures):\n",
    "- Total unique configs: 6\n",
    "- Runs per config: 10\n",
    "- Total workflow runs: 60\n",
    "- Result: Best config balancing accuracy, cost, and speed\n",
    "\n",
    "Output:\n",
    "- One \"best\" configuration file\n",
    "- Detailed comparison of all tested configs\n",
    "- Visualizations showing trade-offs between metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "050f6c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to tmp_workflow/configs/config_b.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a tmp_workflow/configs/config_b.yml\n",
    "optimizer:\n",
    "  output_path: ./tmp_workflow/eval_output/optimizer/\n",
    "  reps_per_param_set: 10 # Number of times to evaluate EACH config (for statistical significance)\n",
    "  eval_metrics: # specifies which evaluatin metrics to optimize for\n",
    "    accuracy: # custom name for the metric\n",
    "      evaluator_name: answer_accuracy  # References the evaluator defined under the 'eval' section\n",
    "      direction: maximize\n",
    "      weight: 1.0 # coefficient of relative importance for the optimizer (defaults to 1.0)\n",
    "    token_efficiency: # custom name for the metric\n",
    "      evaluator_name: token_efficiency # References the evaluator defined under the 'eval' section\n",
    "      direction: minimize\n",
    "      weight: 1.0\n",
    "    latency: # custom name for the metric\n",
    "      evaluator_name: llm_latency # References the evaluator defined under the 'eval' section\n",
    "      direction: minimize\n",
    "      weight: 1.0\n",
    "\n",
    "  numeric:\n",
    "    enabled: true # enables numeric/categorical parameters to be optimized\n",
    "    sampler: grid # uses Optuna GridSearch to determine the unique parameter sets to evaluate\n",
    "\n",
    "  prompt:\n",
    "    enabled: false  # Disable for pure model and hyperparameter comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692dfb0b",
   "metadata": {},
   "source": [
    "<a id=\"dataset\"></a>\n",
    "### 1.2.3) Create an eval dataset\n",
    "\n",
    "The dataset below is intended to be difficult for simple LLM chat completions, because:\n",
    "- Math calculations (questions 1, 2, 5, 7, 9) require precise arithmetic that LLMs often struggle with\n",
    "- Real-time data queries (questions 3, 8) need current information beyond the model's training cutoff\n",
    "- Factual knowledge (questions 4, 6) may be outdated or incorrect without access to recent data\n",
    "- Multi-step reasoning (questions 2, 7) requires combining multiple operations accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c388ff67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tmp_workflow/data/eval_data.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile tmp_workflow/data/eval_data.json\n",
    "[\n",
    "    {\n",
    "        \"id\": \"1\",\n",
    "        \"question\": \"What is 15% of 847?\",\n",
    "        \"answer\": \"The answer is 127.05\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"2\", \n",
    "        \"question\": \"If I invest $10,000 at 5% annual interest compounded monthly for 3 years, how much will I have?\",\n",
    "        \"answer\": \"Approximately $11,614.72\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"3\",\n",
    "        \"question\": \"What is the current weather in Tokyo?\",\n",
    "        \"answer\": \"This requires real-time weather data for Tokyo, Japan.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"4\",\n",
    "        \"question\": \"Who won the FIFA World Cup in 2022 and where was it held?\",\n",
    "        \"answer\": \"Argentina won the 2022 FIFA World Cup, which was held in Qatar.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"5\",\n",
    "        \"question\": \"Calculate the average of these numbers: 23, 45, 67, 89, 12, 34\",\n",
    "        \"answer\": \"The average is 45\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"6\",\n",
    "        \"question\": \"What is the capital of Australia and what is its approximate population?\",\n",
    "        \"answer\": \"Canberra is the capital of Australia with a population of approximately 460,000 people.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"7\",\n",
    "        \"question\": \"If a train travels 120 miles in 2 hours, then 180 miles in 3 hours, what is its average speed over the entire journey?\",\n",
    "        \"answer\": \"The average speed is 60 miles per hour (300 miles / 5 hours).\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"8\",\n",
    "        \"question\": \"Search for information about the latest NASA Mars mission and summarize the key findings.\",\n",
    "        \"answer\": \"Requires web search for current NASA Mars mission information and synthesis of findings.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"9\",\n",
    "        \"question\": \"What is 2 to the power of 10?\",\n",
    "        \"answer\": \"1024\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"10\",\n",
    "        \"question\": \"Who is the current CEO of Microsoft and when did they take the position?\",\n",
    "        \"answer\": \"Satya Nadella has been CEO of Microsoft since February 2014.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b71b0b",
   "metadata": {},
   "source": [
    "<a id=\"optimize-first\"></a>\n",
    "### 1.2.4) Run the optimizer\n",
    "\n",
    "<div style=\"color: red; font-style: italic;\">\n",
    "<strong>Developer warning:</strong> Running the optimizer can take significant time (~30 minutes for search space of n=10) and  LLM inference tokens. Double check your config for unneeded search parameters or reduce the number of samples in the evaluation dataset to reduce cost.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71420933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-24 10:38:54 - WARNING  - nat.experimental.decorators.experimental_warning_decorator:59 - The Optimizer feature is experimental and the API may change in future releases. Future versions may introduce breaking changes without notice. Function: nat.profiler.parameter_optimization.optimizer_runtime.optimize_config\n",
      "2025-10-24 10:38:59 - WARNING  - nat.experimental.decorators.experimental_warning_decorator:59 - The Optimizer feature is experimental and the API may change in future releases. Future versions may introduce breaking changes without notice. Function: nat.profiler.parameter_optimization.parameter_optimizer.optimize_parameters\n",
      "2025-10-24 10:38:59 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:70 - Using Grid sampler for numeric optimization\n",
      "\u001b[32m[I 2025-10-24 10:38:59,418]\u001b[0m A new study created in memory with name: no-name-9ea08d4f-12e1-4fd0-b73b-f70036d0736a\u001b[0m\n",
      "2025-10-24 10:38:59 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:125 - Starting numeric / enum parameter optimization...\n",
      "2025-10-24 10:39:03 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:39:03 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]2025-10-24 10:39:05 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:39:05 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A2025-10-24 10:39:05 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:39:05 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A2025-10-24 10:39:05 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:39:05 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:39:05 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:39:05 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:05 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:39:05 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:05 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:39:05 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:05 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:39:05 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:05 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:39:05 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:05 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:39:05 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:08,  1.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:08,  1.00it/s]\u001b[A\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:01<00:04,  1.94it/s]\u001b[A\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:01<00:02,  3.07it/s]\u001b[A\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:01<00:05,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:01<00:07,  1.09it/s]\u001b[A\u001b[A\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:02<00:05,  1.36it/s]\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:02<00:26,  2.94s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:03<00:06,  1.00it/s]\u001b[A\u001b[A\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:03<00:03,  1.47it/s]\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:04<00:07,  1.17s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:04<00:09,  1.33s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:04<00:05,  1.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:05<00:09,  1.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:06<00:07,  1.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:07<00:07,  1.49s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:07<00:27,  3.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:07<00:14,  2.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:08<00:07,  1.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:08<00:07,  1.85s/it]\u001b[A\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:08<00:10,  2.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:08<01:20,  8.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:10<00:08,  1.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:10<00:37,  4.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:11<00:18,  2.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:11<00:09,  2.35s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:12<00:07,  2.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:13<00:09,  1.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:13<00:12,  3.13s/it]\u001b[A\u001b[A\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:13<00:04,  2.16s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:13<00:48,  6.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:14<00:24,  3.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:14<00:07,  2.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:14<02:13, 14.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:15<00:14,  2.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:15<00:09,  3.05s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:16<00:12,  3.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:16<00:56,  7.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:16<00:27,  3.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:17<00:11,  2.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:17<02:36, 17.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:19<00:11,  2.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:19<01:05,  8.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:19<00:12,  2.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:19<00:09,  3.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:19<00:33,  4.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:20<03:05, 20.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:20<00:19,  3.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:21<00:12,  3.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:22<00:13,  2.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:23<01:19,  9.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:23<00:10,  3.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:24<00:04,  4.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:24<00:11,  5.76s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:25<00:13,  3.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:26<00:10,  5.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:26<00:10,  3.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:26<00:00,  2.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|██████████████| 10/10 [00:00<00:00, 988.80it/s]\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|███████████| 10/10 [00:00<00:00, 989.90it/s]\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:27<00:04,  4.00s/it]\u001b[A\u001b[A\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:27<00:04,  4.84s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:27<00:09,  4.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:28<00:00,  2.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1470.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1471.69it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:28<00:03,  3.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:28<00:12,  6.08s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:28<00:06,  3.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:29<00:02,  2.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:29<00:04,  4.48s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:29<00:16,  4.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:29<00:08,  4.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:29<00:08,  2.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:30<00:04,  2.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:30<00:11,  3.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:30<00:05,  2.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:30<00:03,  3.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:04<00:36,  4.11s/it]2025-10-24 10:39:36 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:31<00:02,  2.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:03<00:30,  3.35s/it]\u001b[A2025-10-24 10:39:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  40%|█████▌        | 4/10 [00:03<00:03,  1.51it/s]\u001b[A2025-10-24 10:39:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:31<00:00,  3.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1398.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1396.10it/s]\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  20%|██▊           | 2/10 [00:05<00:18,  2.27s/it]2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:31<00:15,  3.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:32<00:00,  3.21s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1163.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1160.76it/s]\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:04,  1.84it/s]\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:  90%|████████████▌ | 9/10 [00:05<00:00,  2.69it/s]\u001b[A2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.13it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:32<00:08,  2.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 12.80it/s]\u001b[A\u001b[A2025-10-24 10:39:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:00<00:00, 19.19it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:39:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:33<00:02,  2.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:34<00:05,  2.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:34<00:00,  3.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|██████████████| 10/10 [00:00<00:00, 982.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|███████████| 10/10 [00:00<00:00, 950.66it/s]\n",
      "2025-10-24 10:39:39 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:39 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:03,  2.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:39 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:40 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:00<00:00, 12.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:40 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:40 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:10<00:00,  1.01s/it]2025-10-24 10:39:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:04<00:00,  1.61it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:39:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:05<00:00,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:37<00:02,  2.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:45 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:40<00:00,  4.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg Tokens/LLM_END:   0%|                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1251.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1238.54it/s]\n",
      "2025-10-24 10:39:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:46 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 22.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:46 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:47 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:47 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:42<00:00,  4.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1202.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1200.74it/s]\n",
      "2025-10-24 10:39:48 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:48 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:48 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:48 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:48 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:48 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:48 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:48 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:00<00:00, 20.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:48 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:48 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:48 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:48 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:49 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:50 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:46<00:00,  4.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1220.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1180.20it/s]\n",
      "2025-10-24 10:39:52 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:52 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:52 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:52 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:52 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:52 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:52 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:52 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 22.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:39:52 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:52 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:52 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:52 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:52 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:02<00:00,  4.53it/s]\n",
      "2025-10-24 10:39:53 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:53 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:53 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:53 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:06<00:00,  1.60it/s]\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:08<00:00,  1.17it/s]\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:15<00:00,  1.51s/it]\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:17<00:00,  1.75s/it]\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:39:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:18<00:00,  1.80s/it]\n",
      "\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:21<00:00,  2.17s/it]\u001b[A\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:23<00:00,  2.33s/it]\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:39:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:53<00:00,  5.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1400.58it/s]\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1398.75it/s]\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.22it/s]2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:58 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:00<00:00, 20.13it/s]2025-10-24 10:39:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:39:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:39:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:01 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:01 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:01 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:01 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:01 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:01 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:04<00:00,  2.31it/s]\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:59<00:00,  5.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1419.25it/s]\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1417.67it/s]\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.17it/s]2025-10-24 10:40:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  60%|████████▍     | 6/10 [00:00<00:00, 17.24it/s]2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  90%|████████████▌ | 9/10 [00:00<00:00, 13.13it/s]2025-10-24 10:40:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:04<00:00,  2.30it/s]\n",
      "2025-10-24 10:40:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "\u001b[32m[I 2025-10-24 10:40:09,009]\u001b[0m Trial 0 finished with values: [0.07, 161.2, 17.171] and parameters: {'llms.chat_completion_llm.temperature': 0.0, 'llms.chat_completion_llm.model_name': 'meta/llama-3.1-70b-instruct'}.\u001b[0m\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:40:09 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:40:09 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:40:09 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:40:09 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:40:09 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:40:09 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:40:09 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:40:09 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:40:09 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:40:09 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:40:09 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:06,  1.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:06,  1.41it/s]\u001b[A\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:07,  1.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:00<00:03,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:01<00:01,  3.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:01<00:01,  4.82it/s]\u001b[A\u001b[A\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:02<00:03,  1.99it/s]\u001b[A\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:02<00:03,  1.93it/s]\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:02<00:21,  2.41s/it]\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:02<00:02,  2.50it/s]\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:02<00:09,  1.23s/it]\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:03<00:01,  2.04it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:03<00:29,  3.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:03<00:11,  1.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:04<00:05,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:04<00:07,  1.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:04<00:09,  1.37s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:05<00:02,  1.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:05<00:02,  1.03it/s]\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:05<00:04,  1.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:05<00:04,  1.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:06<00:55,  6.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:07<00:24,  3.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:08<00:05,  1.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:09<01:27,  9.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:09<00:33,  4.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:10<00:17,  2.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:10<00:08,  2.22s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:10<00:10,  1.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:11<00:05,  1.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:11<00:10,  2.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:11<00:03,  1.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:11<01:47, 11.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:12<00:42,  5.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:12<00:15,  3.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:13<00:06,  2.21s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:13<00:22,  3.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:13<00:08,  2.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:13<00:12,  2.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:13<00:05,  1.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:14<02:07, 14.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:14<00:49,  6.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:14<00:08,  2.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:15<00:26,  3.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:15<00:14,  2.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:16<02:29, 16.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:17<00:07,  2.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:18<00:11,  2.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:18<00:14,  2.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:18<01:02,  7.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:18<00:30,  4.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:20<00:19,  3.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:20<00:10,  2.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:20<00:09,  4.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:20<00:10,  5.40s/it]\u001b[A\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:21<00:03,  4.00s/it]\u001b[A\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:22<00:03,  3.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:22<00:12,  3.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:23<00:09,  4.51s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:23<00:03,  3.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:23<00:09,  4.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:23<00:08,  2.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:23<00:03,  3.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:24<00:07,  3.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:24<00:02,  2.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:24<00:03,  3.65s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:25<00:07,  3.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:25<00:08,  2.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:25<00:05,  2.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:25<00:04,  2.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:25<00:03,  3.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:26<00:13,  3.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:26<00:01,  1.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:27<00:02,  2.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:27<00:07,  2.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:28<00:04,  2.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:30<00:02,  2.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:31<00:00,  3.11s/it]\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|██████████████| 10/10 [00:00<00:00, 980.66it/s]\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|███████████| 10/10 [00:00<00:00, 911.65it/s]\n",
      "2025-10-24 10:40:40 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:40 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:03,  2.94it/s]2025-10-24 10:40:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:40 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:40 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:40 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:40 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  60%|████████▍     | 6/10 [00:00<00:00, 16.42it/s]2025-10-24 10:40:40 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:40 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:40 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  90%|████████████▌ | 9/10 [00:00<00:00, 14.48it/s]2025-10-24 10:40:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:41 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:32<00:00,  3.29s/it]\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1087.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1086.75it/s]\n",
      "2025-10-24 10:40:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.06it/s]\u001b[A2025-10-24 10:40:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:00<00:00, 18.62it/s]\u001b[A2025-10-24 10:40:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:34<00:00,  3.43s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1111.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1113.73it/s]\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:34<00:00,  3.45s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1043.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1042.30it/s]\n",
      "2025-10-24 10:40:43 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:03,  2.41it/s]\u001b[A\u001b[A2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.19it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 19.19it/s]\u001b[A\u001b[A2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:43 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 23.53it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:40:43 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:02<00:00,  3.02it/s]\u001b[A2025-10-24 10:40:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:44 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:46 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:46 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:48 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:48 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:06<00:00,  1.50it/s]\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:07<00:00,  1.41it/s]\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:08<00:00,  1.15it/s]\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:50 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:41<00:00,  4.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1418.86it/s]\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1417.81it/s]\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.21it/s]2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 23.17it/s]2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:02<00:00,  4.40it/s]\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:53 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:44<00:00,  4.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1265.86it/s]\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1266.17it/s]\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.05it/s]2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:00<00:00, 19.39it/s]2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:55 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:55 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:55 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:55 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:55 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:55 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:55 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:55 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:55 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:55 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:55 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:55 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:55 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:55 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:03<00:00,  3.07it/s]\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:40:57 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:49<00:00,  4.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|██████████████| 10/10 [00:00<00:00, 630.04it/s]\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|███████████| 10/10 [00:00<00:00, 614.36it/s]\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.01it/s]2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  50%|███████       | 5/10 [00:00<00:00, 13.74it/s]2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:40:59 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  90%|████████████▌ | 9/10 [00:00<00:00, 16.19it/s]2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:40:59 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:00 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:03<00:00,  3.01it/s]\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:02 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:53<00:00,  5.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|██████████████| 10/10 [00:00<00:00, 987.55it/s]\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|███████████| 10/10 [00:00<00:00, 984.99it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:53<00:00,  5.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1308.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1307.04it/s]\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:03,  2.43it/s]2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.27it/s]\u001b[A2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:00<00:00, 16.49it/s]2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 23.54it/s]\u001b[A2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:02 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:05<00:00,  1.82it/s]\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:05<00:00,  1.70it/s]\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:08 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:58<00:00,  5.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|██████████████| 10/10 [00:00<00:00, 603.97it/s]\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|███████████| 10/10 [00:00<00:00, 603.90it/s]\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.11it/s]2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:00<00:00, 19.76it/s]2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:08 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:10 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:10 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:10 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:10 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:10 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:10 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:10 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:10 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:10 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:10 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:03<00:00,  3.08it/s]\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "\u001b[32m[I 2025-10-24 10:41:11,313]\u001b[0m Trial 1 finished with values: [0.09, 154.93, 14.61] and parameters: {'llms.chat_completion_llm.temperature': 0.7, 'llms.chat_completion_llm.model_name': 'meta/llama-3.1-70b-instruct'}.\u001b[0m\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:11 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.7, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:11 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:07,  1.14it/s]\u001b[A\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:08,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:01<00:02,  3.26it/s]\u001b[A\u001b[A\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:01<00:05,  1.51it/s]\u001b[A2025-10-24 10:41:12 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:01<00:15,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:01<00:06,  1.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:01<00:04,  1.59it/s]\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:01<00:03,  2.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:02<00:01,  4.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:02<00:00,  6.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:02<00:06,  1.14it/s]\u001b[A\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:02<00:02,  2.23it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:02<00:24,  2.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:02<00:04,  1.30it/s]\u001b[A\u001b[A\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:02<00:01,  2.94it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:02<00:05,  1.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:14 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:02<00:26,  2.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:02<00:01,  3.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:03<00:03,  1.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:14 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:03<00:28,  3.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:03<00:03,  1.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:14 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:03<00:31,  3.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:03<00:12,  1.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:03<00:06,  1.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:03<00:04,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:03<00:03,  1.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:03<00:01,  2.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:04<00:06,  1.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:03<00:35,  3.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:15 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:04<00:04,  1.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:15 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:04<00:37,  4.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  30%|███████▊                  | 3/10 [00:04<00:07,  1.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:04<00:02,  1.35it/s]\u001b[A\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:04<00:03,  1.24it/s]\u001b[A\u001b[A2025-10-24 10:41:15 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:15 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:04<00:02,  1.51it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:04<00:02,  1.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:16 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:04<00:00,  1.67it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:41:16 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:04<00:01,  1.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:04<00:00,  2.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  40%|██████████▍               | 4/10 [00:04<00:05,  1.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:16 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:05<00:01,  1.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:16 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:05<00:00,  2.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:05<00:00,  3.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:16 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:05<00:00,  2.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  50%|█████████████             | 5/10 [00:05<00:04,  1.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:05<00:01,  1.06it/s]\u001b[A2025-10-24 10:41:17 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:17 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  60%|███████████████▌          | 6/10 [00:05<00:02,  1.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:17 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:17 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:17 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:17 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:06<00:03,  1.05s/it]\u001b[A\u001b[A2025-10-24 10:41:17 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:06<00:02,  1.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:06<00:02,  1.00s/it]\u001b[A\u001b[A2025-10-24 10:41:18 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:18 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:18 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:08<00:00,  1.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 2140.82it/s]\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 2132.66it/s]\n",
      "2025-10-24 10:41:20 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.20it/s]2025-10-24 10:41:20 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:20 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:20 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  40%|█████▌        | 4/10 [00:00<00:00, 11.20it/s]2025-10-24 10:41:20 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:20 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:20 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:00<00:00, 16.24it/s]2025-10-24 10:41:20 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:20 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:20 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:21 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:10<00:00,  1.01s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1474.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1473.18it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:10<00:00,  1.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|██████████████| 10/10 [00:00<00:00, 911.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|███████████| 10/10 [00:00<00:00, 909.28it/s]\n",
      "2025-10-24 10:41:21 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:03,  2.44it/s]\u001b[A2025-10-24 10:41:21 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  30%|████▏         | 3/10 [00:00<00:01,  6.22it/s]\u001b[A2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  40%|█████▌        | 4/10 [00:00<00:00,  6.81it/s]\u001b[A2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:22 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:22 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:05,  1.69it/s]\u001b[A\u001b[A2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  20%|██▊           | 2/10 [00:00<00:02,  3.29it/s]\u001b[A\u001b[A2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  50%|███████       | 5/10 [00:00<00:00,  8.88it/s]\u001b[A\u001b[A2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:01<00:00,  6.83it/s]\u001b[A2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:22 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  90%|████████████▌ | 9/10 [00:01<00:00,  8.96it/s]\u001b[A2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:01<00:00, 10.67it/s]\u001b[A\u001b[A2025-10-24 10:41:22 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:22 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:23 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:23 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:23 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:23 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:12<00:02,  2.72s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:12<00:00,  1.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1733.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1730.75it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:13<00:01,  1.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:02<00:00,  2.82it/s]\u001b[A\u001b[A2025-10-24 10:41:24 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:24 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.18it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:41:24 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:24 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:24 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:24 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:24 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  60%|████████▍     | 6/10 [00:00<00:00, 17.20it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:41:24 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:24 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:24 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:24 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:13<00:00,  1.35s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1266.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1194.45it/s]\n",
      "2025-10-24 10:41:25 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:13<00:08,  2.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:13<00:00,  1.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1552.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1537.28it/s]\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:25 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:04,  2.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:25 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:00<00:00, 14.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 23.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:25 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:05<00:00,  1.31it/s]2025-10-24 10:41:25 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:25 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:14<00:02,  2.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:25 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:26 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:26 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:26 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:27 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:27 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:27 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:27 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:04<00:00,  1.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:29 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:29 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:08<00:00,  1.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:13<00:00,  1.30s/it]\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:34 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:13<00:00,  1.34s/it]\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:15<00:00,  1.50s/it]\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:35 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:23<00:04,  4.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:24<00:00,  2.42s/it]\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1552.07it/s]\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1545.15it/s]\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:24<00:10,  5.14s/it]2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.06it/s]2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:35 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  60%|████████▍     | 6/10 [00:00<00:00, 15.38it/s]2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:36 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:36 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:36 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:36 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:36 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  90%|████████████▌ | 9/10 [00:00<00:00, 14.89it/s]2025-10-24 10:41:36 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:36 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:36 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:36 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:36 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:25<00:04,  4.00s/it]\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:25<00:00,  2.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1179.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1177.41it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:26<00:00,  2.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 2118.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 2111.51it/s]\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:03,  2.27it/s]\u001b[A2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.27it/s]\u001b[A\u001b[A2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:37 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 17.73it/s]\u001b[A2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:37 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 21.84it/s]\u001b[A\u001b[A2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:27<00:00,  2.73s/it]\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1257.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1258.00it/s]\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.24it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:38 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 23.77it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:41:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:39 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:39 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:39 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:39 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:39 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:39 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:39 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:39 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:39 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:39 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:39 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:40 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:03<00:00,  2.60it/s]\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:05<00:00,  1.94it/s]\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:42 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:42 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:05<00:00,  1.68it/s]\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:07<00:00,  1.26it/s]\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "\u001b[32m[I 2025-10-24 10:41:43,479]\u001b[0m Trial 2 finished with values: [0.045, 66.82000000000001, 3.382] and parameters: {'llms.chat_completion_llm.temperature': 0.7, 'llms.chat_completion_llm.model_name': 'meta/llama-3.1-8b-instruct'}.\u001b[0m\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:   0%|                                  | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:43 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={'console': ConsoleLoggingMethodConfig(level='INFO')}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={} function_groups={} llms={'chat_completion_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=1024), 'nim_judge_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-405b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/eval_output/optimizer'), eval_metrics={'accuracy': OptimizerMetric(evaluator_name='answer_accuracy', direction='maximize', weight=1.0), 'token_efficiency': OptimizerMetric(evaluator_name='token_efficiency', direction='minimize', weight=1.0), 'latency': OptimizerMetric(evaluator_name='llm_latency', direction='minimize', weight=1.0)}, reps_per_param_set=10, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=ChatCompletionConfig(system_prompt='You are a helpful AI assistant. Provide clear, accurate, and helpful \\nresponses to user queries. Be concise and informative.\\n', llm_name='chat_completion_llm') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/eval_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='./tmp_workflow/data/eval_data.json'), profiler=None), evaluators={'answer_accuracy': RagasEvaluatorConfig(llm_name='nim_judge_llm', metric='AnswerAccuracy', input_obj_field=None), 'llm_latency': AverageLLMLatencyConfig(max_concurrency=8), 'token_efficiency': AverageTokensPerLLMEndConfig(max_concurrency=8)})\n",
      "2025-10-24 10:41:43 - WARNING  - nat.profiler.utils:137 - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function register_chat_completion by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:01,  4.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:01,  4.79it/s]\u001b[A\u001b[A\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:01,  4.51it/s]\u001b[A2025-10-24 10:41:43 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:43 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "Running workflow:  20%|█████▏                    | 2/10 [00:00<00:01,  6.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:03,  2.97it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:41:43 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:43 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:03,  2.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:43 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:03,  2.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:04,  1.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:04,  1.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  10%|██▌                       | 1/10 [00:00<00:05,  1.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:00<00:00,  8.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  70%|██████████████████▏       | 7/10 [00:00<00:00,  9.09it/s]\u001b[A\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:00<00:00, 10.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:00<00:00, 10.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:00<00:00, 11.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:00<00:00, 11.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:00<00:00, 10.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:00<00:00, 10.18it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:00<00:00,  9.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:00<00:00, 10.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  80%|████████████████████▊     | 8/10 [00:00<00:00, 10.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:44 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:45 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:45 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:45 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:45 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:45 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:45 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:02<00:00,  4.59it/s]\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1738.28it/s]\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1693.51it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:02<00:00,  4.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 2214.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 2203.59it/s]\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:46 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:02<00:00,  2.89it/s]2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.33it/s]\u001b[A2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:00<00:00, 16.86it/s]2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:46 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:46 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:46 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 13.68it/s]\u001b[A2025-10-24 10:41:46 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:46 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:46 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:03<00:00,  2.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:03<00:00,  2.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:03<00:00,  2.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|███████████████| 10/10 [00:00<00:00, 51.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|████████████| 10/10 [00:00<00:00, 51.41it/s]\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1208.00it/s]\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1210.55it/s]\n",
      "2025-10-24 10:41:47 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:04,  1.94it/s]\u001b[A\u001b[A2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:47 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:47 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  60%|████████▍     | 6/10 [00:00<00:00, 16.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  60%|████████▍     | 6/10 [00:00<00:00, 11.84it/s]\u001b[A\u001b[A2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:47 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:47 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:47 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  90%|████████████▌ | 9/10 [00:00<00:00, 12.14it/s]\u001b[A\u001b[A2025-10-24 10:41:47 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:48 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:05<00:00,  1.94it/s]\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1467.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1473.65it/s]\n",
      "2025-10-24 10:41:48 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:49 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:05<00:00,  1.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1292.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1172.05it/s]\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:49 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:49 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:05,  1.52it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:49 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 13.26it/s]\u001b[A\u001b[A\u001b[A2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 23.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:49 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:49 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:49 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:49 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:49 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:50 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:50 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:50 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:05<00:00,  1.46it/s]\u001b[A2025-10-24 10:41:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:51 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:51 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:53 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:53 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:06<00:00,  1.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A2025-10-24 10:41:53 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:53 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:05<00:00,  1.90it/s]\n",
      "2025-10-24 10:41:54 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:54 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:54 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:54 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:54 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:11<00:00, 10.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:11<00:00, 10.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Running workflow:  90%|███████████████████████▍  | 9/10 [00:11<00:00, 10.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:06<00:00,  1.47it/s]\u001b[A\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:08<00:00,  1.18it/s]\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:08<00:00,  1.13it/s]\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:55 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:56 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:12<00:00,  1.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1842.68it/s]\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1721.23it/s]\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.13it/s]2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:00<00:00, 19.89it/s]2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:56 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:57 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:41:58 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:03<00:00,  3.08it/s]\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:41:59 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:19<00:00,  1.97s/it]\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1245.15it/s]\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1213.31it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:19<00:00,  1.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1943.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1988.10it/s]\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:03,  2.45it/s]2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.23it/s]\u001b[A2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  50%|███████       | 5/10 [00:00<00:00, 11.26it/s]2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  80%|███████████▏  | 8/10 [00:00<00:00, 23.88it/s]\u001b[A2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:00<00:00, 12.98it/s]2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:03 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "Running workflow: 100%|█████████████████████████| 10/10 [00:20<00:00,  2.10s/it]\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency:   0%|                        | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Avg LLM Latency: 100%|█████████████| 10/10 [00:00<00:00, 1696.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Evaluating Avg Tokens/LLM_END: 100%|██████████| 10/10 [00:00<00:00, 1691.25it/s]\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  10%|█▍            | 1/10 [00:00<00:02,  3.10it/s]\u001b[A\u001b[A2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  70%|█████████▊    | 7/10 [00:00<00:00, 18.70it/s]\u001b[A\u001b[A2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:04 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:05 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:06 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:07 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:04<00:00,  1.75it/s]2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:42:09 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:05<00:00,  1.98it/s]\u001b[A\u001b[A\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:09 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:06<00:00,  1.59it/s]\n",
      "Evaluating Ragas nv_accuracy: 100%|█████████████| 10/10 [00:06<00:00,  1.48it/s]\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/eval_output/workflow_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/llm_latency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/token_efficiency_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "2025-10-24 10:42:10 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/eval_output/answer_accuracy_output.json\n",
      "\u001b[32m[I 2025-10-24 10:42:10,057]\u001b[0m Trial 3 finished with values: [0.027500000000000004, 13.38, 0.745] and parameters: {'llms.chat_completion_llm.temperature': 0.0, 'llms.chat_completion_llm.model_name': 'meta/llama-3.1-8b-instruct'}.\u001b[0m\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:10 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 3\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:231 - Parallel coordinates plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_parallel_coordinates.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:325 - Pairwise matrix plot saved to: tmp_workflow/eval_output/optimizer/plots/pareto_pairwise_matrix.png\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/eval_output/optimizer/plots\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "2025-10-24 10:42:11 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!nat optimize --config_file tmp_workflow/configs/config_b.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f79ce00",
   "metadata": {},
   "source": [
    "<a id=\"interpret-optimizer-first\"></a>\n",
    "### 1.2.5) Interpret first optimizer run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6029eeeb",
   "metadata": {},
   "source": [
    "**Understanding Evaluation Outputs**\n",
    "\n",
    "This evaluation will have generated two artifacts for analysis at the `output_dir` specified in `config_b.yml`:\n",
    " - **`answer_accuracy_output.json`**\n",
    " - **`workflow_output.json`**\n",
    " - **`llm_latency_output.json`**\n",
    " - **`token_efficiency_output.json`**\n",
    "\n",
    "**Interpreting `trajectory_accuracy_output.json`**\n",
    "\n",
    "The `trajectory_accuracy_output.json` file contains the results of agent trajectory evaluation.\n",
    "\n",
    "**Top-level fields:**\n",
    "- **`average_score`** - Mean trajectory accuracy score across all evaluated examples (0.0 to 1.0)\n",
    "- **`eval_output_items`** - Array of individual evaluation results for each test case\n",
    "\n",
    "**Per-item fields:**\n",
    "- **`id`** - Unique identifier for the test case\n",
    "- **`score`** - Trajectory accuracy score for this specific example (0.0 to 1.0)\n",
    "- **`reasoning`** - Evaluation reasoning, either:\n",
    "  - String containing error message if evaluation failed\n",
    "  - Object with:\n",
    "    - **`reasoning`** - LLM judge's explanation of the score\n",
    "    - **`trajectory`** - Array of [AgentAction, Output] pairs showing the agent's execution path\n",
    "\n",
    "The trajectory accuracy evaluator assesses whether the agent used appropriate tools, followed a logical sequence of steps, and efficiently reached the correct answer.\n",
    "\n",
    "**Interpreting `workflow_output.json`**\n",
    "\n",
    "The `workflow_output.json` file contains the raw execution results from running the workflow on each test case.\n",
    "\n",
    "**Top-level fields:**\n",
    "- **`output_items`** - Array of workflow execution results for each test case in the dataset\n",
    "\n",
    "**Per-item fields:**\n",
    "- **`id`** - Unique identifier matching the test case ID\n",
    "- **`input_obj`** - The input question or prompt sent to the workflow\n",
    "- **`output_obj`** - The final answer generated by the workflow\n",
    "- **`trajectory`** - Detailed execution trace containing:\n",
    "  - **`event_type`** - Type of event (e.g., `LLM_START`, `LLM_END`, `TOOL_START`, `TOOL_END`, `SPAN_START`, `SPAN_END`)\n",
    "  - **`event_timestamp`** - Unix timestamp of when the event occurred\n",
    "  - **`metadata`** - Event-specific data including:\n",
    "    - Tool names and inputs\n",
    "    - LLM prompts and responses\n",
    "    - Token counts (`prompt_tokens`, `completion_tokens`)\n",
    "    - Model names\n",
    "    - Function names\n",
    "    - Error information\n",
    "\n",
    "The workflow output provides complete observability into each execution, enabling detailed analysis of agent behavior, performance profiling, and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab620774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Optimization Results\n",
      "================================================================================\n",
      "\n",
      "Trials Summary:\n",
      " number  values_accuracy  values_token_efficiency  values_latency             datetime_start          datetime_complete               duration params_llms.chat_completion_llm.model_name  params_llms.chat_completion_llm.temperature                                                                                                                                                                                                       rep_scores  system_attrs_grid_id                                                                                                                                  system_attrs_search_space    state  pareto_optimal\n",
      "      0           0.0700                   161.20          17.171 2025-10-24 10:38:59.418266 2025-10-24 10:40:09.009520 0 days 00:01:09.591254                meta/llama-3.1-70b-instruct                                          0.0 [[0.1, 164.2, 9.75], [0.0, 161.3, 11.21], [0.1, 160.1, 12.61], [0.0, 161.3, 13.28], [0.1, 160.8, 15.17], [0.1, 162.3, 17.8], [0.0, 160.2, 19.46], [0.1, 161.0, 21.64], [0.1, 161.0, 23.91], [0.1, 159.8, 26.88]]                     0 {'llms.chat_completion_llm.model_name': ['meta/llama-3.1-8b-instruct', 'meta/llama-3.1-70b-instruct'], 'llms.chat_completion_llm.temperature': [0.0, 0.7]} COMPLETE           False\n",
      "      1           0.0900                   154.93          14.610 2025-10-24 10:40:09.009751 2025-10-24 10:41:11.313751 0 days 00:01:02.304000                meta/llama-3.1-70b-instruct                                          0.7 [[0.1, 161.0, 9.01], [0.1, 160.4, 9.13], [0.0, 107.7, 10.48], [0.1, 161.0, 12.02], [0.1, 151.9, 12.67], [0.1, 160.4, 13.99], [0.1, 164.3, 16.33], [0.1, 161.5, 19.45], [0.1, 159.7, 19.94], [0.1, 161.4, 23.08]]                     1 {'llms.chat_completion_llm.model_name': ['meta/llama-3.1-8b-instruct', 'meta/llama-3.1-70b-instruct'], 'llms.chat_completion_llm.temperature': [0.0, 0.7]} COMPLETE            True\n",
      "      2           0.0450                    66.82           3.382 2025-10-24 10:41:11.313901 2025-10-24 10:41:43.478982 0 days 00:00:32.165081                 meta/llama-3.1-8b-instruct                                          0.7                [[0.1, 150.4, 9.76], [0.1, 164.9, 3.7], [0.1, 121.8, 5.19], [0.0, 9.4, 0.08], [0.0, 49.0, 4.31], [0.1, 17.9, 0.48], [0.025, 51.2, 2.59], [0.0, 9.4, 0.16], [0.0, 9.4, 0.87], [0.025, 84.8, 6.68]]                     2 {'llms.chat_completion_llm.model_name': ['meta/llama-3.1-8b-instruct', 'meta/llama-3.1-70b-instruct'], 'llms.chat_completion_llm.temperature': [0.0, 0.7]} COMPLETE            True\n",
      "      3           0.0275                    13.38           0.745 2025-10-24 10:41:43.479119 2025-10-24 10:42:10.057892 0 days 00:00:26.578773                 meta/llama-3.1-8b-instruct                                          0.0                    [[0.025, 32.6, 0.63], [0.0, 25.3, 2.18], [0.1, 9.4, 0.09], [0.025, 9.4, 1.71], [0.0, 9.4, 0.09], [0.0, 9.4, 0.09], [0.0, 9.4, 0.27], [0.0, 9.4, 0.09], [0.1, 9.4, 0.81], [0.025, 10.1, 1.49]]                     3 {'llms.chat_completion_llm.model_name': ['meta/llama-3.1-8b-instruct', 'meta/llama-3.1-70b-instruct'], 'llms.chat_completion_llm.temperature': [0.0, 0.7]} COMPLETE            True\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Load the optimizer results\n",
    "trials_df_path = Path(\"tmp_workflow/eval_output/optimizer/trials_dataframe_params.csv\")\n",
    "\n",
    "if trials_df_path.exists():\n",
    "    trials_df = pd.read_csv(trials_df_path)\n",
    "\n",
    "    print(\"Grid Search Optimization Results\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nTrials Summary:\")\n",
    "    print(trials_df.to_string(index=False))\n",
    "    print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3836ec19",
   "metadata": {},
   "source": [
    "TODO: revise this after pareto plot update\n",
    "\n",
    "The results above show:\n",
    " \n",
    "**Grid Search Optimization Summary:**\n",
    "- The optimizer evaluated all combinations of models and temperatures defined in the search space\n",
    "- Each configuration was tested multiple times (repetitions) to account for variability\n",
    "- Three key metrics were tracked: accuracy, token efficiency (tokens used), and latency (response time)\n",
    " \n",
    " **Understanding the Statistics:**\n",
    "- **Mean**: Average performance across all repetitions for each model\n",
    "- **Standard Deviation (±)**: Measure of variability in performance\n",
    "- **95% Confidence Interval**: Range where we expect 95% of results to fall\n",
    "\n",
    "**Key Insights:**\n",
    " - Different models show different trade-offs between accuracy, efficiency, and speed\n",
    "- Temperature settings affect response variability and quality\n",
    "- The \"Best Configuration\" represents the optimal balance based on the weighted combination of all metrics\n",
    " \n",
    "**Interpreting Your Results:**\n",
    "When you run this optimization, look for:\n",
    "- Which model/temperature combination achieves the highest aggregated accuracy\n",
    "- How token efficiency varies between models (lower is more efficient)\n",
    "- Latency differences (lower is faster)\n",
    "- The confidence intervals to understand result stability\n",
    "\n",
    "The optimizer automatically selects the best configuration and saves it to `optimized_config.yml` for use in production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59876571",
   "metadata": {},
   "source": [
    "<a id=\"optimize-tool-calling-agents\"></a>\n",
    "# 2.0) Optimized model and parameter selection for tool-calling agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7223a3b2",
   "metadata": {},
   "source": [
    "<a id=\"create-triage-agent\"></a>\n",
    "## 2.1) Create a tool-calling agent\n",
    "As we explained above, in many real-world applications straightforward chat completions requests may not be adequate without agentic tool-calling integration. Therefore, for the next exercise we are going to build a similar optimize pipeline for an advanced tool calling agent: the [Alert Triage Agent](https://github.com/NVIDIA/NeMo-Agent-Toolkit/tree/develop/examples/advanced_agents/alert_triage_agent). This agent uses tool calling to automate the triage of server-monitoring alerts. It demonstrates how to build an intelligent troubleshooting workflow using NeMo Agent toolkit and LangGraph.\n",
    "\n",
    "The Alert Triage Agent is an advanced example that demonstrates:\n",
    "- **Multi-tool orchestration** - Dynamically selects and uses diagnostic tools\n",
    "- **Structured report generation** - Creates comprehensive analysis reports\n",
    "- **Root cause categorization** - Classifies alerts into predefined categories\n",
    "- **Offline evaluation mode** - Test with synthetic data before live deployment\n",
    "\n",
    "We aim to demonstrate the power of model evaluation and optimization on agentic AI platforms. There are many foundational models to choose as your agent's backbone and academic benchmarks are not always representative of potential performance on your institutional data (refer to training data leakage and data domain shift research for more motivation).\n",
    "\n",
    "<div style=\"color: red; font-style: italic;\">\n",
    "<strong>Note:</strong> As the Alert Triage Agent is not shipped with the NAT PyPi package, we will either clone it from GitHub (by selecting your branch of choice), or if the package was installed with the `-e` editable code flag, we can work locally. We will parameterize the path to this agent to easily alter the configuration in the next cell\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a101122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Alert Triage Agent Installation\n",
      "============================================================\n",
      "\n",
      "Options:\n",
      "  - Enter 'local' for editable install from local repository\n",
      "  - Enter a branch name (e.g., 'develop', 'main') for git install\n",
      "============================================================\n",
      "\n",
      "Installing alert triage agent in editable mode from local repository...\n",
      "Obtaining file:///Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of nat-alert-triage-agent to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement nvidia-nat~=1.4 (from nat-alert-triage-agent) (from versions: 1.1.0a20251020, 1.2.0a20250813, 1.2.0rc5, 1.2.0rc6, 1.2.0rc7, 1.2.0rc8, 1.2rc9, 1.2.0rc10, 1.2.0, 1.2.1rc1, 1.2.1, 1.3.dev0, 1.3.0.dev2, 1.3a0, 1.3a20250818, 1.3a20250819, 1.3.0a20250822, 1.3.0a20250823, 1.3.0a20250824, 1.3.0a20250826, 1.3.0a20250827, 1.3.0a20250828, 1.3.0a20250829, 1.3.0a20250830, 1.3.0a20250831, 1.3.0a20250901, 1.3.0a20250902, 1.3.0a20250904, 1.3.0a20250906, 1.3.0a20250909, 1.3.0a20250910, 1.3.0a20250917, 1.3.0a20250922, 1.3.0a20250923, 1.3.0a20250924, 1.3.0a20250925, 1.3.0a20250926, 1.3.0a20250928, 1.3.0a20250929, 1.3.0a20250930, 1.3.0a20251001, 1.3.0a20251002, 1.3.0a20251004, 1.3.0a20251005, 1.3.0a20251006, 1.3.0a20251007, 1.3.0a20251008, 1.3.0a20251009, 1.3.0a20251012, 1.3.0a20251013, 1.3.0a20251021, 1.3.0a20251022, 1.3.0a20251023, 1.3.0a20251024, 1.3.0rc1, 1.3.0rc2, 1.3.0rc3, 1.3.0rc4, 1.3.0rc5, 1.3.0rc6, 1.4.0a20251008, 1.4.0a20251010, 1.4.0a20251011, 1.4.0a20251012, 1.4.0a20251013, 1.4.0a20251014, 1.4.0a20251015, 1.4.0a20251021, 1.4.0a20251022, 1.4.0a20251023, 1.4.0a20251024)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for nvidia-nat~=1.4\u001b[0m\u001b[31m\n",
      "\u001b[0m✓ Installed from local path: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/notebooks/../../examples/advanced_agents/alert_triage_agent\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Simple input prompt for branch selection\n",
    "print(\"=\" * 60)\n",
    "print(\"Alert Triage Agent Installation\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nOptions:\")\n",
    "print(\"  - Enter 'local' for editable install from local repository\")\n",
    "print(\"  - Enter a branch name (e.g., 'develop', 'main') for git install\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "branch_name = input(\"\\nEnter your choice: \").strip()\n",
    "\n",
    "if branch_name.lower() == 'local':\n",
    "    # Local editable install\n",
    "    print(\"\\nInstalling alert triage agent in editable mode from local repository...\")\n",
    "\n",
    "    # Try to find the local path relative to current directory\n",
    "    from pathlib import Path\n",
    "    # path-check-skip-next-line\n",
    "    local_path = Path('../../examples/advanced_agents/alert_triage_agent')\n",
    "\n",
    "    if local_path.exists():\n",
    "        get_ipython().system(f'pip install -e {local_path}')\n",
    "        print(f\"✓ Installed from local path: {local_path.absolute()}\")\n",
    "    else:\n",
    "        print(f\"✗ Error: Local path not found: {local_path.absolute()}\")\n",
    "        print(\"Make sure you're running this from the correct directory\")\n",
    "else:\n",
    "    # Git install from specified branch\n",
    "    print(f\"\\nInstalling alert triage agent from branch: {branch_name}\")\n",
    "    get_ipython().system(f'pip install --no-deps \"git+https://github.com/NVIDIA/NeMo-Agent-Toolkit.git@{branch_name}#subdirectory=examples/advanced_agents/alert_triage_agent\"')\n",
    "    print(f\"✓ Installed from git branch: {branch_name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1fc34f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package data directory: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data\n"
     ]
    }
   ],
   "source": [
    "import importlib.resources\n",
    "\n",
    "# Find the installed package data directory\n",
    "package_data = importlib.resources.files('nat_alert_triage_agent').joinpath('data')\n",
    "\n",
    "maintenance_csv = str(package_data / 'maintenance_static_dataset.csv')\n",
    "offline_csv = str(package_data / 'offline_data.csv')\n",
    "benign_json = str(package_data / 'benign_fallback_offline_data.json')\n",
    "offline_json = str(package_data / 'offline_data.json')\n",
    "\n",
    "print(f\"Package data directory: {package_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc40fd05",
   "metadata": {},
   "source": [
    "<a id=\"configure-triage-agent\"></a>\n",
    "## 2.2) Configure the tool-calling agent\n",
    "\n",
    "**Configuring the Alert Triage Agent**\n",
    "\n",
    "The Alert Triage Agent requires several components:\n",
    "\n",
    "1. **Diagnostic Tools** - Hardware checks, network connectivity, performance monitoring, telemetry analysis\n",
    "2. **Sub-agents** - Telemetry metrics analysis agent that coordinates multiple telemetry tools\n",
    "3. **Categorizer** - Classifies root causes into predefined categories\n",
    "4. **Maintenance Check** - Filters out alerts during maintenance windows\n",
    "\n",
    "We'll create a **local configuration file** and run in **offline mode** using synthetic data.\n",
    "\n",
    "In the configuration file, you can see the list of LLMs that we have predefined to be compared when the optimizer runs. We will only run the initial search across two models, for brevity and token efficiency. However, you can uncomment the entire list of 11 models (or add [more models](https://catalog.ngc.nvidia.com/)) to run a more robust search. This model will be used as the agent's backbone LLM for reasoning steps. The `tool_reasoning_llm` and `nim_rag_eval_llm` remain fixed to `meta/llama-3.1-70b-instruct`, but in a modified evaluation these models could be evaluated as well. \n",
    "```\n",
    "- Meta: llama-3.1-8b-instruct\n",
    "- Meta: llama-3.1-70b-instruct\n",
    "- Meta: llama-3.1-405b-instruct\n",
    "- Meta: llama-3.3-3b-instruct\n",
    "- Meta: llama-3.3-70b-instruct\n",
    "- Meta: llama-4-scout-17b-16e-instruct\n",
    "- OpenAI: gpt-oss-20b\n",
    "- OpenAI: gpt-oss-120b\n",
    "- IBM: granite-3.3-8b-instruct\n",
    "- MistralAI: mistral-small-3.1-24b-instruct-2503\n",
    "- MistralAI: mistral-medium-3-instruct\n",
    "```\n",
    "\n",
    "We additionally provide two different vlaues for `temperature` to exemplify concurrent model and parameter searches:\n",
    "```\n",
    "- 0.0\n",
    "- 0.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97b2e49",
   "metadata": {},
   "source": [
    "<div style=\"color: red; font-style: italic;\">\n",
    "<strong>Developer warning:</strong> Running the optimizer can consume a significant amount of LLM inference tokens. To protect users from unexpected costs only 2 models have been left uncommented in the config below. Uncomment models to increase the search space.\n",
    "</div>\n",
    "\n",
    "We will create a YAML configuration file using Python code rather than a static file. This approach allows us to dynamically reference the package data directory and ensures the configuration is created in the notebook's working directory, making it easier to modify and experiment with different settings for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8f1940e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./tmp_workflow/configs/alert_triage_config_model_selection.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tmp_workflow/configs/alert_triage_config_model_selection.yml\n",
    "# path-check-skip-begin\n",
    "functions:\n",
    "  hardware_check:\n",
    "    _type: hardware_check\n",
    "    llm_name: tool_reasoning_llm\n",
    "    offline_mode: true\n",
    "  host_performance_check:\n",
    "    _type: host_performance_check\n",
    "    llm_name: tool_reasoning_llm\n",
    "    offline_mode: true\n",
    "  monitoring_process_check:\n",
    "    _type: monitoring_process_check\n",
    "    llm_name: tool_reasoning_llm\n",
    "    offline_mode: true\n",
    "  network_connectivity_check:\n",
    "    _type: network_connectivity_check\n",
    "    llm_name: tool_reasoning_llm\n",
    "    offline_mode: true\n",
    "  telemetry_metrics_host_heartbeat_check:\n",
    "    _type: telemetry_metrics_host_heartbeat_check\n",
    "    llm_name: tool_reasoning_llm\n",
    "    offline_mode: true\n",
    "  telemetry_metrics_host_performance_check:\n",
    "    _type: telemetry_metrics_host_performance_check\n",
    "    llm_name: tool_reasoning_llm\n",
    "    offline_mode: true\n",
    "  telemetry_metrics_analysis_agent:\n",
    "    _type: telemetry_metrics_analysis_agent\n",
    "    tool_names:\n",
    "      - telemetry_metrics_host_heartbeat_check\n",
    "      - telemetry_metrics_host_performance_check\n",
    "    llm_name: agent_llm\n",
    "  maintenance_check:\n",
    "    _type: maintenance_check\n",
    "    llm_name: agent_llm\n",
    "    static_data_path: PLACEHOLDER_maintenance_static_dataset.csv\n",
    "  categorizer:\n",
    "    _type: categorizer\n",
    "    llm_name: agent_llm\n",
    "\n",
    "workflow:\n",
    "  _type: alert_triage_agent\n",
    "  tool_names:\n",
    "    - hardware_check\n",
    "    - host_performance_check\n",
    "    - monitoring_process_check\n",
    "    - network_connectivity_check\n",
    "    - telemetry_metrics_analysis_agent\n",
    "  llm_name: agent_llm\n",
    "  offline_mode: true\n",
    "  offline_data_path: PLACEHOLDER_offline_data.csv\n",
    "  benign_fallback_data_path: PLACEHOLDER_benign_fallback_offline_data.json\n",
    "\n",
    "llms:\n",
    "  agent_llm:\n",
    "    _type: nim\n",
    "    model_name: meta/llama-3.1-8b-instruct\n",
    "    temperature: 0.0\n",
    "    max_tokens: 2048\n",
    "    optimizable_params:\n",
    "      - model_name\n",
    "      - temperature\n",
    "    search_space:\n",
    "      model_name:\n",
    "        values:\n",
    "          - meta/llama-3.1-8b-instruct\n",
    "          - meta/llama-3.1-70b-instruct\n",
    "          # - meta/llama-3.1-405b-instruct\n",
    "          # - meta/llama-3.3-3b-instruct\n",
    "          # - meta/llama-3.3-70b-instruct\n",
    "          # - meta/llama-4-scout-17b-16e-instruct\n",
    "          # - openai/gpt-oss-20b\n",
    "          # - openai/gpt-oss-120b\n",
    "          # - ibm/granite-3.3-8b-instruct\n",
    "          # - mistralai/mistral-small-3.1-24b-instruct-2503\n",
    "          # - mistralai/mistral-medium-3-instruct\n",
    "      temperature:\n",
    "        values:\n",
    "          - 0.0\n",
    "          - 0.5\n",
    "  tool_reasoning_llm:\n",
    "    _type: nim\n",
    "    model_name: meta/llama-3.1-70b-instruct\n",
    "    temperature: 0.2\n",
    "    max_tokens: 2048\n",
    "  nim_rag_eval_llm:\n",
    "    _type: nim\n",
    "    model_name: meta/llama-3.1-70b-instruct\n",
    "    max_tokens: 8\n",
    "\n",
    "eval:\n",
    "  general:\n",
    "    output_dir: ./tmp_workflow/alert_triage_model_selection_output/\n",
    "    dataset:\n",
    "      _type: json\n",
    "      file_path: PLACEHOLDER_offline_data.json\n",
    "  evaluators:\n",
    "    classification_accuracy:\n",
    "      _type: classification_accuracy\n",
    "    rag_accuracy:\n",
    "      _type: ragas\n",
    "      metric: AnswerAccuracy\n",
    "      llm_name: nim_rag_eval_llm\n",
    "  profiler:\n",
    "    token_uniqueness_forecast: true\n",
    "    workflow_runtime_forecast: true\n",
    "    compute_llm_metrics: true\n",
    "    csv_exclude_io_text: true\n",
    "    prompt_caching_prefixes:\n",
    "      enable: true\n",
    "      min_frequency: 0.1\n",
    "    bottleneck_analysis:\n",
    "      enable_nested_stack: true\n",
    "    concurrency_spike_analysis:\n",
    "      enable: true\n",
    "      spike_threshold: 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e86bf",
   "metadata": {},
   "source": [
    "Above we have defined the `SearchSpace` to include two different LLMs (variants of Meta's llama 3.1 model), and temperature of 0.0 and 0.5 (making 4 unique combinations via grid search).\n",
    "\n",
    "Next, let's append sime simple optimizer settings to our configuration. We will optimize specifically for the predefined `classification_accuracy` evaluator, use a grid search sampler, and **disable prompt optimization**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c5d0fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to ./tmp_workflow/configs/alert_triage_config_model_selection.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a ./tmp_workflow/configs/alert_triage_config_model_selection.yml\n",
    "optimizer:\n",
    "  output_path: ./tmp_workflow/alert_triage_model_selection_output/optimizer/\n",
    "  reps_per_param_set: 1\n",
    "  eval_metrics:\n",
    "    classification_accuracy:\n",
    "      evaluator_name: classification_accuracy\n",
    "      direction: maximize\n",
    "  numeric:\n",
    "    enabled: true\n",
    "    sampler: grid\n",
    "  prompt:\n",
    "    enabled: false\n",
    "# path-check-skip-end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099c4dc5",
   "metadata": {},
   "source": [
    "Before running, let's replace the placeholder paths in our config, depending on where we have installed the Alert Traige Agent. This step is only needed for compatibility of this notebook to source NAT in multiple ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20ec99f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Config written with data paths from: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data\n"
     ]
    }
   ],
   "source": [
    "# Replace placeholder paths with actual package data paths\n",
    "import importlib.resources\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "\n",
    "# Get the package data path\n",
    "package_data = importlib.resources.files('nat_alert_triage_agent').joinpath('data')\n",
    "\n",
    "# Read the YAML file\n",
    "config_path = Path('./tmp_workflow/configs/alert_triage_config_model_selection.yml')\n",
    "with open(config_path, 'r') as f:\n",
    "    config_content = f.read()\n",
    "\n",
    "# Replace placeholders with actual paths\n",
    "replacements = {\n",
    "    'PLACEHOLDER_maintenance_static_dataset.csv': str(package_data / 'maintenance_static_dataset.csv'),\n",
    "    'PLACEHOLDER_offline_data.csv': str(package_data / 'offline_data.csv'),\n",
    "    'PLACEHOLDER_benign_fallback_offline_data.json': str(package_data / 'benign_fallback_offline_data.json'),\n",
    "    'PLACEHOLDER_offline_data.json': str(package_data / 'offline_data.json')\n",
    "}\n",
    "\n",
    "for placeholder, actual_path in replacements.items():\n",
    "    config_content = config_content.replace(placeholder, actual_path)\n",
    "\n",
    "# Write back to file\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(f\"✓ Config written with data paths from: {package_data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299df6c9",
   "metadata": {},
   "source": [
    "<a id=\"test-triage-agent\"></a>\n",
    "## 2.3) Test the tool-calling agent\n",
    "\n",
    "Let's test the Alert Triage Agent with a single alert. This alert is an \"InstanceDown\" alert that, according to the offline dataset, is actually a false positive (the system is healthy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34b468a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-24 10:45:54 - INFO     - nat.cli.commands.start:192 - Starting NAT from config file: 'tmp_workflow/configs/alert_triage_config_model_selection.yml'\n",
      "2025-10-24 10:45:54 - INFO     - nat_alert_triage_agent:104 - Preloaded test data from: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/offline_data.csv\n",
      "2025-10-24 10:45:54 - INFO     - nat_alert_triage_agent:108 - Preloaded benign fallback data from: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/benign_fallback_offline_data.json\n",
      "2025-10-24 10:45:54 - INFO     - nat_alert_triage_agent:80 - ================================================Running in offline mode=================================================\n",
      "\n",
      "Configuration Summary:\n",
      "--------------------\n",
      "Workflow Type: alert_triage_agent\n",
      "Number of Functions: 9\n",
      "Number of Function Groups: 0\n",
      "Number of LLMs: 3\n",
      "Number of Embedders: 0\n",
      "Number of Memory: 0\n",
      "Number of Object Stores: 0\n",
      "Number of Retrievers: 0\n",
      "Number of TTC Strategies: 0\n",
      "Number of Authentication Providers: 0\n",
      "\n",
      "2025-10-24 10:45:54 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-0.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:48:24 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "2025-10-24 10:48:24 - INFO     - nat.front_ends.console.console_front_end_plugin:102 - --------------------------------------------------\n",
      "\u001b[32mWorkflow Result:\n",
      "['**Alert Summary**\\nInstance test-instance-0.example.com is down\\n\\n**Collected Metrics**\\n* `hardware_check`: The instance is up and running, with no hardware issues detected.\\n* `telemetry_metrics_analysis_agent`: The CPU usage is within a moderate range, with no signs of high CPU usage.\\n\\n**Analysis**\\nThe collected metrics suggest that the instance is operational and there are no signs of hardware issues or high CPU usage. However, the periodic surges in CPU usage may indicate a need for further investigation to ensure that they are not indicative of any underlying issues.\\n\\n**Recommended Actions**\\n* Investigate the cause of the periodic surges in CPU usage to ensure that they are not indicative of any underlying issues.\\n* Review the monitoring alert details to determine the specific trigger condition.\\n* Verify that the IPMI output is current and not delayed.\\n* Check the system logs for any error messages or warnings that may indicate a hardware or software issue.\\n\\n**Alert Status**\\nAbnormal but benign\\n\\n## Root Cause Category\\nrepetitive_behavior\\n\\nThe report indicates that the instance is operational and there are no signs of hardware issues or high CPU usage, but there are periodic surges in CPU usage that may warrant further investigation. This suggests a recurring or periodic behavior pattern, which aligns with the repetitive_behavior category.']\u001b[39m\n",
      "--------------------------------------------------\n",
      "2025-10-24 10:48:24 - INFO     - nat_alert_triage_agent:164 - Cleaning up\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "alert = {\n",
    "    \"alert_id\": 0,\n",
    "    \"alert_name\": \"InstanceDown\",\n",
    "    \"host_id\": \"test-instance-0.example.com\",\n",
    "    \"severity\": \"critical\",\n",
    "    \"description\": (\n",
    "        \"Instance test-instance-0.example.com is not available for scraping for the last 5m. \"\n",
    "        \"Please check: - instance is up and running; - monitoring service is in place and running; \"\n",
    "        \"- network connectivity is ok\"\n",
    "    ),\n",
    "    \"summary\": \"Instance test-instance-0.example.com is down\",\n",
    "    \"timestamp\": \"2025-04-28T05:00:00.000000\"\n",
    "}\n",
    "\n",
    "!nat run --config_file tmp_workflow/configs/alert_triage_config_model_selection.yml --input '{json.dumps(alert)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ac49a9",
   "metadata": {},
   "source": [
    "After running the cell above, we have confirmed that the tool calling agent is properly configured and ready for a naive evaluation. This evaluation will be our performance baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ef191",
   "metadata": {},
   "source": [
    "<a id=\"eval-triage-agent1\"></a>\n",
    "## 2.4) Evaluate the tool-calling agent (naive parameters)\n",
    "\n",
    "*using `nat eval`...*\n",
    "\n",
    "Now let's run a full evaluation on the Alert Triage Agent using the complete offline dataset. This dataset contains seven alerts with different root causes:\n",
    "\n",
    "- **False positives** - System appears healthy despite alert\n",
    "- **Hardware issues** - Hardware failures or degradation  \n",
    "- **Software issues** - Malfunctioning monitoring services\n",
    "- **Maintenance** - Scheduled maintenance windows\n",
    "- **Repetitive behavior** - Benign recurring patterns\n",
    "\n",
    "The evaluation will measure:\n",
    "1. **Classification Accuracy** - How well the agent categorizes root causes\n",
    "2. **Answer Accuracy** - How well the generated reports match expected outcomes (using RAGAS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55c4fcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-24 10:49:01 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: tmp_workflow/configs/alert_triage_config_model_selection.yml\n",
      "2025-10-24 10:49:05 - INFO     - nat_alert_triage_agent:104 - Preloaded test data from: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/offline_data.csv\n",
      "2025-10-24 10:49:05 - INFO     - nat_alert_triage_agent:108 - Preloaded benign fallback data from: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/benign_fallback_offline_data.json\n",
      "2025-10-24 10:49:05 - INFO     - nat_alert_triage_agent:80 - ================================================Running in offline mode=================================================\n",
      "Running workflow:   0%|                                   | 0/7 [00:00<?, ?it/s]2025-10-24 10:49:05 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-0.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:49:05 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-1.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:49:05 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-2.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:49:05 - INFO     - nat_alert_triage_agent:258 - Host: [test-instance-3.example.com] is under maintenance according to the maintenance database\n",
      "2025-10-24 10:49:36 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-4.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:49:36 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-5.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:49:36 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-6.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:49:36 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  14%|███▊                       | 1/7 [00:30<03:04, 30.71s/it]2025-10-24 10:49:53 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  29%|███████▋                   | 2/7 [00:47<01:51, 22.32s/it]2025-10-24 10:50:57 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  43%|███████████▌               | 3/7 [01:51<02:46, 41.67s/it]2025-10-24 10:51:46 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  57%|███████████████▍           | 4/7 [02:40<02:13, 44.45s/it]2025-10-24 10:52:01 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  71%|███████████████████▎       | 5/7 [02:55<01:07, 33.79s/it]2025-10-24 10:52:30 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  86%|███████████████████████▏   | 6/7 [03:24<00:32, 32.03s/it]2025-10-24 10:55:17 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow: 100%|███████████████████████████| 7/7 [06:11<00:00, 53.01s/it]\n",
      "Evaluating classification accuracy:   0%|                 | 0/7 [00:00<?, ?it/s]\n",
      "Evaluating classification accuracy: 100%|█████████| 7/7 [00:00<00:00, 26.85it/s]\u001b[A\n",
      "2025-10-24 10:55:17 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  14%|██▏            | 1/7 [00:00<00:05,  1.01it/s]\u001b[A2025-10-24 10:55:18 - INFO     - nat.utils.exception_handlers.automatic_retries:159 - Retrying on exception [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
      "{'status': 429, 'title': 'too many requests'}\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  57%|████████▌      | 4/7 [00:01<00:00,  3.10it/s]\u001b[A\n",
      "Evaluating Ragas nv_accuracy:  86%|████████████▊  | 6/7 [00:01<00:00,  3.82it/s]\u001b[A\n",
      "Evaluating Ragas nv_accuracy: 100%|███████████████| 7/7 [00:02<00:00,  2.87it/s]\u001b[A\n",
      "2025-10-24 10:55:19 - INFO     - nat_alert_triage_agent:164 - Cleaning up\n",
      "2025-10-24 10:55:19 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:55:19 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/alert_triage_model_selection_output/workflow_output.json\n",
      "2025-10-24 10:55:19 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/alert_triage_model_selection_output/classification_accuracy_output.json\n",
      "2025-10-24 10:55:19 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/alert_triage_model_selection_output/rag_accuracy_output.json\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!nat eval --config_file ./tmp_workflow/configs/alert_triage_config_model_selection.yml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe817e6",
   "metadata": {},
   "source": [
    "**Understanding Alert Triage Evaluation Results**\n",
    "\n",
    "The evaluation generates several output files in the `alert_triage_output` directory:\n",
    "\n",
    "1. **classification_accuracy_output.json** - Root cause classification metrics\n",
    "   - Shows accuracy, precision, recall, and F1 scores for each category\n",
    "   - Contains confusion matrix for detailed analysis\n",
    "   \n",
    "2. **rag_accuracy_output.json** - Answer quality metrics\n",
    "   - Measures how well generated reports match expected outcomes\n",
    "   - Uses LLM-as-a-judge to evaluate report quality\n",
    "\n",
    "3. **workflow_output.json** - Complete execution traces\n",
    "   - Contains full agent trajectories with tool calls\n",
    "   - Includes generated reports for each alert\n",
    "   - Shows token usage and performance metrics\n",
    "\n",
    "Let's examine the classification accuracy results:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754384df",
   "metadata": {},
   "source": [
    "We see that the classification accuracy results are around 43% based on RAG accuracy results of 46%.\n",
    "\n",
    "Next we will run the optimizer over a variety of models and some reasonable hyperparameters, then use that optimal configuration and run the evaluation again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ddbbe01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy Results:\n",
      "Average Score: 57.00%\n",
      "\n",
      "Per-Alert Results:\n",
      "  Alert 0: Score=1.00 - The prediction false_positive is correct. (label: false_positive)\n",
      "  Alert 1: Score=1.00 - The prediction hardware is correct. (label: hardware)\n",
      "  Alert 2: Score=0.00 - The prediction need_investigation is incorrect. (label: software)\n",
      "  Alert 3: Score=0.00 - The prediction ## alert summary is incorrect. (label: maintenance)\n",
      "  Alert 4: Score=1.00 - The prediction software is correct. (label: software)\n",
      "  Alert 5: Score=1.00 - The prediction false_positive is correct. (label: false_positive)\n",
      "  Alert 6: Score=0.00 - The prediction software is incorrect. (label: repetitive_behavior)\n",
      "\n",
      "\n",
      "RAG Accuracy Results:\n",
      "Average Score: 60.71%\n",
      "Total Alerts Evaluated: 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and display classification accuracy results\n",
    "# path-check-skip-next-line\n",
    "with open('./tmp_workflow/alert_triage_model_selection_output/classification_accuracy_output.json') as f:\n",
    "    classification_results = json.load(f)\n",
    "\n",
    "print(\"Classification Accuracy Results:\")\n",
    "print(f\"Average Score: {classification_results['average_score']:.2%}\")\n",
    "print(\"\\nPer-Alert Results:\")\n",
    "for item in classification_results['eval_output_items']:\n",
    "    print(f\"  Alert {item['id']}: Score={item['score']:.2f} - {item['reasoning']}\")\n",
    "\n",
    "# Load and display RAG accuracy results\n",
    "# path-check-skip-next-line\n",
    "with open('./tmp_workflow/alert_triage_model_selection_output/rag_accuracy_output.json') as f:\n",
    "    rag_results = json.load(f)\n",
    "\n",
    "print(\"\\n\\nRAG Accuracy Results:\")\n",
    "print(f\"Average Score: {rag_results['average_score']:.2%}\")\n",
    "print(f\"Total Alerts Evaluated: {len(rag_results['eval_output_items'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c2cf1",
   "metadata": {},
   "source": [
    "<a id=\"optimize-triage-agent\"></a>\n",
    "## 2.5) Optimize the tool-calling agent's LLM\n",
    "\n",
    "*using `nat optimize`...*\n",
    "\n",
    "Next we will run `nat optimize` for the Alert Traige Agent using a GridSearch sweep over the `OptimizableField`s in `alert_triage_config.yml`. In this case, we are just comparing backbone LLM models for the core agent, not the `tool_reasoning_llm`. Optimizable fields have been previously explained in this notebook, but in this case we are going to run a similar optimization pass over a complex tool-calling agent to demonstrate the power of `nat optimize` at scale.\n",
    "\n",
    "<div style=\"color: red; font-style: italic;\">\n",
    "<strong>Developer warning:</strong> Running the optimizer can take significant time (~30 minutes for search space of n=10) and  LLM inference tokens. Double check your config for unneeded search parameters prior to running.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ddd831f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-24 10:57:58 - WARNING  - nat.experimental.decorators.experimental_warning_decorator:59 - The Optimizer feature is experimental and the API may change in future releases. Future versions may introduce breaking changes without notice. Function: nat.profiler.parameter_optimization.optimizer_runtime.optimize_config\n",
      "2025-10-24 10:58:18 - WARNING  - nat.experimental.decorators.experimental_warning_decorator:59 - The Optimizer feature is experimental and the API may change in future releases. Future versions may introduce breaking changes without notice. Function: nat.profiler.parameter_optimization.parameter_optimizer.optimize_parameters\n",
      "2025-10-24 10:58:18 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:70 - Using Grid sampler for numeric optimization\n",
      "\u001b[32m[I 2025-10-24 10:58:18,680]\u001b[0m A new study created in memory with name: no-name-e747c825-0d94-4852-99fc-7201af9cc160\u001b[0m\n",
      "2025-10-24 10:58:18 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:125 - Starting numeric / enum parameter optimization...\n",
      "2025-10-24 10:58:23 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={'hardware_check': HardwareCheckToolConfig(description='This tool checks hardware health status using IPMI monitoring to detect power state, hardware degradation, and anomalies that could explain alerts. Args: host_id: str', llm_name='tool_reasoning_llm', prompt=\"You are analyzing IPMI metrics to support host monitoring and alert triage. Use the provided IPMI output to assess overall system status. Your goals are to:\\n\\n1. Determine the system's current power state.\\n2. Identify any signs of hardware degradation or failure.\\n3. Flag any anomalies that could explain why a monitoring alert was triggered.\\n\\nReview the data carefully and summarize your assessment in a clear and structured format.\\n\\nIPMI Output:\\n{input_data}\\n\\nFormat your response as follows:\\n\\nPower Status: ON / OFF\\nHardware Health: Normal / Issues Detected\\nObserved Anomalies: [List any irregularities or warning signs]\\nPossible Cause of Alert: [e.g., hardware issue, thermal spike, power fluctuation, no clear issue]\\nNext Steps: [Recommended actions or checks for further triage]\", offline_mode=True), 'host_performance_check': HostPerformanceCheckToolConfig(description='This tool retrieves CPU usage, memory usage, and hardware I/O usage details for a given host. Args: host_id: str', llm_name='tool_reasoning_llm', parsing_prompt='You are given system performance data captured from a host. Your task is to extract and organize the information into a clean, structured JSON format. The input contains system details and performance metrics, such as CPU, memory, and disk I/O.\\n\\nFollow these instructions:\\n\\n1. Identify metric categories dynamically based on the line prefixes or column headers (e.g., \"Mem:\", \"Swap:\", \"CPU:\", \"Device:\").\\n2. For each category, extract the numerical values and map them to meaningful field names.\\n3. Group related fields under sections such as \"memory_usage\", \"swap_usage\", \"cpu_usage\", \"disk_io\", etc.\\n4. Use consistent, readable key names for all fields.\\n5. Return **only** the final JSON object — no explanations or extra text.\\n\\nHere is the input data:\\n{input_data}', analysis_prompt='You are analyzing system metrics to assess CPU and memory usage. Use the output below to determine whether CPU or memory usage is abnormally high, identify which processes are consuming the most resources, and assess whether the usage patterns could explain a recent alert.\\n\\nInstructions:\\n1. Evaluate overall CPU and memory usage levels.\\n2. List the top resource-consuming processes, including their name, PID, %CPU, and %MEM.\\n3. Identify any potential causes of high usage (e.g., memory leak, runaway process, legitimate high load).\\n4. Recommend possible next steps for investigation or mitigation.\\n\\nFormat your response as a structured summary:\\n\\nCPU Usage: Normal / High (X% usage)\\nMemory Usage: Normal / High (X% usage)\\nTop Resource-Consuming Processes: [Process name, PID, %CPU, %MEM]\\nPotential Cause of High Usage: [e.g., runaway process, heavy load, memory leak]\\nNext Steps: [Suggested mitigation actions]\\n\\nSystem Metrics Output:\\n{input_data}\\n', offline_mode=True), 'monitoring_process_check': MonitoringProcessCheckToolConfig(description='This tool checks the status of critical monitoring processes and services on a target host by executing system commands. Args: host_id: str', llm_name='tool_reasoning_llm', prompt='You are checking whether the telegraf service is running on the server. Use the monitoring output below to verify its status. If it’s not running, identify possible reasons and assess the impact.\\n\\nInstructions:\\n1. Check if the telegraf process is present and active.\\n2. Evaluate the potential impact of telegraf not running on system availability or monitoring.\\n3. Identify likely causes for the process not running.\\n\\nFormat your response as a structured summary:\\n* **Telegraf Running:** Yes / No\\n* **Potential Impact:** [e.g., host seems down to the monitoring system, delayed alerting]\\n* **Possible Cause:** [e.g., process crash, misconfiguration, resource constraints]\\n* **Next Steps:** [e.g., restart telegraf, check logs]\\n\\nMonitoring Output:\\n{input_data}', offline_mode=True), 'network_connectivity_check': NetworkConnectivityCheckToolConfig(description='This tool checks network connectivity of a host by running ping and socket connection tests. Args: host_id: str', llm_name='tool_reasoning_llm', prompt='You are assisting with alert triage by checking the network connectivity status of a host. Use the outputs from `ping` and `telnet` commands to determine whether the host is reachable. If connectivity issues are detected, analyze the possible root causes and provide a structured summary of your findings.\\n\\nInstructions:\\n1. Interpret the `ping` and `telnet` results to assess host reachability.\\n2. Determine whether there is a connectivity issue.\\n3. Identify potential causes, such as network failure, firewall restrictions, or service unavailability.\\n4. Recommend appropriate next steps for troubleshooting or escalation.\\n\\nFormat your response as a structured summary:\\n\\nPing Status: Successful / Failed\\nTelnet Status: Connected / Failed\\nPotential Cause of Connectivity Issue: [e.g., network failure, firewall rules, service outage, no issue]\\nNext Steps: [e.g., check network logs, restart network services, escalate issue, or no action needed]\\n\\nPing Output:\\n{ping_data}\\n\\nTelnet Output:\\n{telnet_data}', offline_mode=True), 'telemetry_metrics_host_heartbeat_check': TelemetryMetricsHostHeartbeatCheckToolConfig(description=\"This tool checks if a host's telemetry monitoring service is reporting heartbeat metrics. This tells us if the host is up and running. Args: host_id: str\", llm_name='tool_reasoning_llm', prompt=\"The following is the telemetry metrics fetched for the host to see if it's been up and running (if result is empty, then the monitoring service on the host is down):\\n{data}\\nBased on the data, summarize the fetched data and provide a conclusion of the host's running status.\", offline_mode=True, metrics_url=''), 'telemetry_metrics_host_performance_check': TelemetryMetricsHostPerformanceCheckToolConfig(description='This tool checks the performance of the host by analyzing the CPU usage timeseries. Args: host_id: str', llm_name='tool_reasoning_llm', prompt=\"You are an expert on analyzing CPU usage timeseries. Periodic usage peaks are expected benign system behavior.\\nUser will provide data in the format of a list of lists, where each sublist contains two elements: timestamp and CPU usage percentage. User will also provide statistics on the timeseries. Write a markdown report about what was observed in the timeseries.\\n\\nExample format:\\n# CPU Usage Analysis Report\\nThe data analysis is performed on 14 days of CPU usage percentage data.\\n\\n## Data Statistics\\ndata start and end time, data point interval, CPU usage statistics\\n\\n## Observations\\nany patterns observed? Should be one of the below cases:\\n- Are there any cyclic usage surges?\\n  - What is the cycle?\\n  - What is the high and low CPU usage of the pattern?\\n- Is there one anomalous peak?\\n  - When did it happen?\\n  - What is it like before and after?\\n- No obvious pattern? A mix of patterns? => it's normal flutuation of the system (max usage less than 60%)\\n  - What is the fluctuation range?\\n\\n## Conclusion\\nSummarize the observation.\\nCategories:\\n- peak in the data means the high CPU usage is an anomaly and requires attention\\n- periodic behvior means the high usage is benign\\n- overall moderate (max usage less than 60%) usage means no issue in the system\\n\\n## Pattern Label\\nAnomalous Peak/Periodic Surges/Normal Fluctuations\\n\", offline_mode=True, metrics_url=''), 'telemetry_metrics_analysis_agent': TelemetryMetricsAnalysisAgentConfig(description='This is a telemetry metrics tool used to monitor remotely collected telemetry data. It checks server heartbeat data to determine whether the server is up and running and analyzes CPU usage patterns over the past 14 days to identify potential CPU issues. Args: host_id: str, alert_type: str', tool_names=['telemetry_metrics_host_heartbeat_check', 'telemetry_metrics_host_performance_check'], llm_name='agent_llm', prompt=\"You arg a helpful alert triage assistant. Your task is to investigate an alert that was just triggered on a specific host. You will be given two inputs:\\n- `host_id`: the identifier of the host where the alert occurred.\\n- `alert_type`: the type of alert that triggered.\\n\\nUse the tools provided below to collect relevant telemetry data for the specified host:\\n\\nTools:\\n- `telemetry_metrics_host_heartbeat_check`: Use this to check the server's heartbeat and determine if the host is currently up and responsive.\\n- `telemetry_metrics_host_performance_check`: Use this to analyze CPU usage trends over the past 14 days and identify abnormal patterns.\\n\\nInstructions:\\n1. Run the appropriate tools based on the host and alert type.\\n2. Collect and include all relevant output from the tools in your response.\\n3. Analyze the data and provide reasoning to help determine whether the telemetry supports or explains the triggered alert.\\n\\nYour response should include:\\n- Raw data from each tool\\n- A concise summary of findings\\n- Any insights or hypotheses that explain the alert\"), 'maintenance_check': MaintenanceCheckToolConfig(description='Check if a host is under maintenance during the time of an alert to help determine if the alert can be deprioritized.', llm_name='agent_llm', prompt='User will provide you with a system alert represented in JSON format. You know for a fact that there is maintenance happening for the host. Maintenance start time for this host is : [{maintenance_start_str}]; end time is: [{maintenance_end_str}] (end time empty means that there is not yet a set end time for the maintenance on the host)\\nGenerate a markdown report in the following format:\\n\\n## Alert Summary\\n(summary of what happened in the alert JSON data)\\n\\n## Collected Metrics\\n(lay out the maintenance information)\\n\\n## Analysis\\n(Describe the maintenance status of this host)\\n\\n## Recommended Actions\\n(Bullet point list: write how the user may not need to worry about this alert given that the host is under maintenance, and they could check if the issue persists afterward)\\n\\n## Alert Status\\n(can deprioritize the investigation of the alert, host under maintenance)', static_data_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/maintenance_static_dataset.csv', skip_maintenance_check=False), 'categorizer': CategorizerToolConfig(description='This is a categorization tool used at the end of the pipeline.', llm_name='agent_llm', prompt='You will be given a system-generated alert triage report. Your job is to read the report carefully and determine the most likely root cause of the issue. Then, categorize the root cause into one of the following predefined categories:\\n\\n**Valid Categories**\\n- `software`: The alert was triggered due to a malfunctioning or inactive monitoring service (e.g., Telegraf not running).\\n- `network_connectivity`: The host is not reachable via ping or curl, or there are signs of connection issues due to blocked ports, broken services, or firewall rules (e.g., telnet fails).\\n- `hardware`: The alert is caused by a hardware failure or degradation.\\n- `repetitive_behavior`: The alert is triggered by a recurring or periodic behavior pattern (e.g., regular CPU spikes or memory surges).\\n- `false_positive`: No clear signs of failure or degradation; system appears healthy and no suspicious pattern is found.\\n- `need_investigation`: The report contains conflicting, ambiguous, or insufficient information to determine a clear root cause.\\n\\n**Response Format**\\n- Line 1: Output only the category name (e.g., `hardware`)\\n- Line 2: Briefly explain your reasoning based on the contents of the report.\\n- Example response:\\nnetwork_connectivity\\nPing and curl to the host both failed, and telnet to the monitored port timed out, indicating a likely connectivity or firewall issue.\\n\\n**Important Guidelines**\\n- Base your categorization only on evidence presented in the report.\\n- If no category clearly fits, default to `need_investigation`.')} function_groups={} llms={'agent_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=2048), 'tool_reasoning_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.2, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=2048), 'nim_rag_eval_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/alert_triage_model_selection_output/optimizer'), eval_metrics={'classification_accuracy': OptimizerMetric(evaluator_name='classification_accuracy', direction='maximize', weight=1.0)}, reps_per_param_set=1, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=AlertTriageAgentWorkflowConfig(tool_names=['hardware_check', 'host_performance_check', 'monitoring_process_check', 'network_connectivity_check', 'telemetry_metrics_analysis_agent'], llm_name='agent_llm', offline_mode=True, offline_data_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/offline_data.csv', benign_fallback_data_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/benign_fallback_offline_data.json', agent_prompt='**Role**\\nYou are a Triage Agent responsible for diagnosing and troubleshooting system alerts in real time. Your goal is to determine whether an alert indicates a true issue, identify the root cause, and provide a clear, structured triage report to assist system analysts.\\n\\n\\n**Instructions**\\n\\n1. **Analyze the Alert**\\n   Begin by interpreting the incoming alert. Identify its type (e.g., *InstanceDown*, *HighCPUUsage*) and note any relevant details.\\n\\n2. **Select and Use Diagnostic Tools**\\n   Based on the alert type, choose the most relevant tools to gather system metrics. Use each tool only once per alert.\\n\\n   - `hardware_check`: Retrieves server power status and hardware health via IPMI. Useful for diagnosing instance down alerts or suspected hardware failures.\\n   - `host_performance_check`: Collects system-level CPU and memory usage using commands like `top` and `ps`. Use this to identify host\\'s resource (CPR and memory) usage bottlenecks.\\n   - `monitoring_process_check`: Checks whether critical processes are running on the host. Useful for verifying system functionality during instance down or degraded performance.\\n   - `network_connectivity_check`: Tests host connectivity through ping, telnet, and HTTP health checks. Helps determine if the server is reachable from the network.\\n   - `telemetry_metrics_analysis_agent`: Pulls telemetry metrics to check host status and analyze usage trends. Effective for validating instance uptime and system load over time.\\n\\n   Once you\\'ve received outputs from all selected tools, **pause to analyze them before proceeding further**.\\n\\n3. **Correlate Data and Determine Root Cause**\\n   - Evaluate the retrieved metrics against the alert details.\\n   - Determine if the alert reflects a real problem or is a false positive.\\n   - If an issue is detected, identify likely causes—such as hardware failure, performance bottlenecks, or network issues.\\n\\n4. **Generate a Structured Triage Report (in Markdown format)**\\n   Organize your findings clearly under these sections:\\n\\n   - **Alert Summary**: Brief description of the alert received.\\n   - **Collected Metrics**: Outputs from the diagnostic tools used.\\n   - **Analysis**: Interpretation of the data and how it relates to the alert.\\n   - **Recommended Actions**: Suggested next steps to mitigate or resolve the issue.\\n   - **Alert Status**: Choose one — \"Valid\", \"Abnormal but benign\", or \"False alarm\".\\n\\n\\n**Important Rules**\\n- Do not call the same tool more than once per alert.\\n- Analyze tool outputs before taking any additional action.\\n- Stay concise, structured, and actionable.') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/alert_triage_model_selection_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/offline_data.json'), profiler=None), evaluators={'classification_accuracy': ClassificationEvaluatorConfig(), 'rag_accuracy': RagasEvaluatorConfig(llm_name='nim_rag_eval_llm', metric='AnswerAccuracy', input_obj_field=None)})\n",
      "2025-10-24 10:58:23 - INFO     - nat_alert_triage_agent:104 - Preloaded test data from: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/offline_data.csv\n",
      "2025-10-24 10:58:23 - INFO     - nat_alert_triage_agent:108 - Preloaded benign fallback data from: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/benign_fallback_offline_data.json\n",
      "2025-10-24 10:58:23 - INFO     - nat_alert_triage_agent:80 - ================================================Running in offline mode=================================================\n",
      "Running workflow:   0%|                                   | 0/7 [00:00<?, ?it/s]2025-10-24 10:58:24 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-0.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:58:24 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-1.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:58:24 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-2.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:58:24 - INFO     - nat_alert_triage_agent:258 - Host: [test-instance-3.example.com] is under maintenance according to the maintenance database\n",
      "2025-10-24 10:58:28 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-4.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:58:28 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-5.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:58:28 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-6.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:58:28 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  14%|███▊                       | 1/7 [00:03<00:20,  3.43s/it]2025-10-24 10:58:48 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  29%|███████▋                   | 2/7 [00:24<01:08, 13.63s/it]2025-10-24 10:58:54 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  43%|███████████▌               | 3/7 [00:29<00:39,  9.84s/it]2025-10-24 10:58:58 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  57%|███████████████▍           | 4/7 [00:33<00:22,  7.64s/it]2025-10-24 10:59:30 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  71%|███████████████████▎       | 5/7 [01:05<00:32, 16.38s/it]2025-10-24 10:59:34 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  86%|███████████████████████▏   | 6/7 [01:09<00:12, 12.19s/it]2025-10-24 10:59:52 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow: 100%|███████████████████████████| 7/7 [01:28<00:00, 12.59s/it]\n",
      "Evaluating classification accuracy:   0%|                 | 0/7 [00:00<?, ?it/s]\n",
      "Evaluating classification accuracy: 100%|█████████| 7/7 [00:00<00:00, 37.55it/s]\u001b[A\n",
      "2025-10-24 10:59:53 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  14%|██▏            | 1/7 [00:00<00:03,  1.60it/s]\u001b[A2025-10-24 10:59:53 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  29%|████▎          | 2/7 [00:00<00:01,  2.87it/s]\u001b[A2025-10-24 10:59:53 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "2025-10-24 10:59:53 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy: 100%|███████████████| 7/7 [00:01<00:00,  4.77it/s]\u001b[A\n",
      "2025-10-24 10:59:54 - INFO     - nat_alert_triage_agent:164 - Cleaning up\n",
      "2025-10-24 10:59:54 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 10:59:54 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/alert_triage_model_selection_output/workflow_output.json\n",
      "2025-10-24 10:59:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/alert_triage_model_selection_output/classification_accuracy_output.json\n",
      "2025-10-24 10:59:54 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/alert_triage_model_selection_output/rag_accuracy_output.json\n",
      "\u001b[32m[I 2025-10-24 10:59:54,207]\u001b[0m Trial 0 finished with value: 0.29 and parameters: {'llms.agent_llm.temperature': 0.0, 'llms.agent_llm.model_name': 'meta/llama-3.1-70b-instruct'}. Best is trial 0 with value: 0.29.\u001b[0m\n",
      "2025-10-24 10:59:54 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={'hardware_check': HardwareCheckToolConfig(description='This tool checks hardware health status using IPMI monitoring to detect power state, hardware degradation, and anomalies that could explain alerts. Args: host_id: str', llm_name='tool_reasoning_llm', prompt=\"You are analyzing IPMI metrics to support host monitoring and alert triage. Use the provided IPMI output to assess overall system status. Your goals are to:\\n\\n1. Determine the system's current power state.\\n2. Identify any signs of hardware degradation or failure.\\n3. Flag any anomalies that could explain why a monitoring alert was triggered.\\n\\nReview the data carefully and summarize your assessment in a clear and structured format.\\n\\nIPMI Output:\\n{input_data}\\n\\nFormat your response as follows:\\n\\nPower Status: ON / OFF\\nHardware Health: Normal / Issues Detected\\nObserved Anomalies: [List any irregularities or warning signs]\\nPossible Cause of Alert: [e.g., hardware issue, thermal spike, power fluctuation, no clear issue]\\nNext Steps: [Recommended actions or checks for further triage]\", offline_mode=True), 'host_performance_check': HostPerformanceCheckToolConfig(description='This tool retrieves CPU usage, memory usage, and hardware I/O usage details for a given host. Args: host_id: str', llm_name='tool_reasoning_llm', parsing_prompt='You are given system performance data captured from a host. Your task is to extract and organize the information into a clean, structured JSON format. The input contains system details and performance metrics, such as CPU, memory, and disk I/O.\\n\\nFollow these instructions:\\n\\n1. Identify metric categories dynamically based on the line prefixes or column headers (e.g., \"Mem:\", \"Swap:\", \"CPU:\", \"Device:\").\\n2. For each category, extract the numerical values and map them to meaningful field names.\\n3. Group related fields under sections such as \"memory_usage\", \"swap_usage\", \"cpu_usage\", \"disk_io\", etc.\\n4. Use consistent, readable key names for all fields.\\n5. Return **only** the final JSON object — no explanations or extra text.\\n\\nHere is the input data:\\n{input_data}', analysis_prompt='You are analyzing system metrics to assess CPU and memory usage. Use the output below to determine whether CPU or memory usage is abnormally high, identify which processes are consuming the most resources, and assess whether the usage patterns could explain a recent alert.\\n\\nInstructions:\\n1. Evaluate overall CPU and memory usage levels.\\n2. List the top resource-consuming processes, including their name, PID, %CPU, and %MEM.\\n3. Identify any potential causes of high usage (e.g., memory leak, runaway process, legitimate high load).\\n4. Recommend possible next steps for investigation or mitigation.\\n\\nFormat your response as a structured summary:\\n\\nCPU Usage: Normal / High (X% usage)\\nMemory Usage: Normal / High (X% usage)\\nTop Resource-Consuming Processes: [Process name, PID, %CPU, %MEM]\\nPotential Cause of High Usage: [e.g., runaway process, heavy load, memory leak]\\nNext Steps: [Suggested mitigation actions]\\n\\nSystem Metrics Output:\\n{input_data}\\n', offline_mode=True), 'monitoring_process_check': MonitoringProcessCheckToolConfig(description='This tool checks the status of critical monitoring processes and services on a target host by executing system commands. Args: host_id: str', llm_name='tool_reasoning_llm', prompt='You are checking whether the telegraf service is running on the server. Use the monitoring output below to verify its status. If it’s not running, identify possible reasons and assess the impact.\\n\\nInstructions:\\n1. Check if the telegraf process is present and active.\\n2. Evaluate the potential impact of telegraf not running on system availability or monitoring.\\n3. Identify likely causes for the process not running.\\n\\nFormat your response as a structured summary:\\n* **Telegraf Running:** Yes / No\\n* **Potential Impact:** [e.g., host seems down to the monitoring system, delayed alerting]\\n* **Possible Cause:** [e.g., process crash, misconfiguration, resource constraints]\\n* **Next Steps:** [e.g., restart telegraf, check logs]\\n\\nMonitoring Output:\\n{input_data}', offline_mode=True), 'network_connectivity_check': NetworkConnectivityCheckToolConfig(description='This tool checks network connectivity of a host by running ping and socket connection tests. Args: host_id: str', llm_name='tool_reasoning_llm', prompt='You are assisting with alert triage by checking the network connectivity status of a host. Use the outputs from `ping` and `telnet` commands to determine whether the host is reachable. If connectivity issues are detected, analyze the possible root causes and provide a structured summary of your findings.\\n\\nInstructions:\\n1. Interpret the `ping` and `telnet` results to assess host reachability.\\n2. Determine whether there is a connectivity issue.\\n3. Identify potential causes, such as network failure, firewall restrictions, or service unavailability.\\n4. Recommend appropriate next steps for troubleshooting or escalation.\\n\\nFormat your response as a structured summary:\\n\\nPing Status: Successful / Failed\\nTelnet Status: Connected / Failed\\nPotential Cause of Connectivity Issue: [e.g., network failure, firewall rules, service outage, no issue]\\nNext Steps: [e.g., check network logs, restart network services, escalate issue, or no action needed]\\n\\nPing Output:\\n{ping_data}\\n\\nTelnet Output:\\n{telnet_data}', offline_mode=True), 'telemetry_metrics_host_heartbeat_check': TelemetryMetricsHostHeartbeatCheckToolConfig(description=\"This tool checks if a host's telemetry monitoring service is reporting heartbeat metrics. This tells us if the host is up and running. Args: host_id: str\", llm_name='tool_reasoning_llm', prompt=\"The following is the telemetry metrics fetched for the host to see if it's been up and running (if result is empty, then the monitoring service on the host is down):\\n{data}\\nBased on the data, summarize the fetched data and provide a conclusion of the host's running status.\", offline_mode=True, metrics_url=''), 'telemetry_metrics_host_performance_check': TelemetryMetricsHostPerformanceCheckToolConfig(description='This tool checks the performance of the host by analyzing the CPU usage timeseries. Args: host_id: str', llm_name='tool_reasoning_llm', prompt=\"You are an expert on analyzing CPU usage timeseries. Periodic usage peaks are expected benign system behavior.\\nUser will provide data in the format of a list of lists, where each sublist contains two elements: timestamp and CPU usage percentage. User will also provide statistics on the timeseries. Write a markdown report about what was observed in the timeseries.\\n\\nExample format:\\n# CPU Usage Analysis Report\\nThe data analysis is performed on 14 days of CPU usage percentage data.\\n\\n## Data Statistics\\ndata start and end time, data point interval, CPU usage statistics\\n\\n## Observations\\nany patterns observed? Should be one of the below cases:\\n- Are there any cyclic usage surges?\\n  - What is the cycle?\\n  - What is the high and low CPU usage of the pattern?\\n- Is there one anomalous peak?\\n  - When did it happen?\\n  - What is it like before and after?\\n- No obvious pattern? A mix of patterns? => it's normal flutuation of the system (max usage less than 60%)\\n  - What is the fluctuation range?\\n\\n## Conclusion\\nSummarize the observation.\\nCategories:\\n- peak in the data means the high CPU usage is an anomaly and requires attention\\n- periodic behvior means the high usage is benign\\n- overall moderate (max usage less than 60%) usage means no issue in the system\\n\\n## Pattern Label\\nAnomalous Peak/Periodic Surges/Normal Fluctuations\\n\", offline_mode=True, metrics_url=''), 'telemetry_metrics_analysis_agent': TelemetryMetricsAnalysisAgentConfig(description='This is a telemetry metrics tool used to monitor remotely collected telemetry data. It checks server heartbeat data to determine whether the server is up and running and analyzes CPU usage patterns over the past 14 days to identify potential CPU issues. Args: host_id: str, alert_type: str', tool_names=['telemetry_metrics_host_heartbeat_check', 'telemetry_metrics_host_performance_check'], llm_name='agent_llm', prompt=\"You arg a helpful alert triage assistant. Your task is to investigate an alert that was just triggered on a specific host. You will be given two inputs:\\n- `host_id`: the identifier of the host where the alert occurred.\\n- `alert_type`: the type of alert that triggered.\\n\\nUse the tools provided below to collect relevant telemetry data for the specified host:\\n\\nTools:\\n- `telemetry_metrics_host_heartbeat_check`: Use this to check the server's heartbeat and determine if the host is currently up and responsive.\\n- `telemetry_metrics_host_performance_check`: Use this to analyze CPU usage trends over the past 14 days and identify abnormal patterns.\\n\\nInstructions:\\n1. Run the appropriate tools based on the host and alert type.\\n2. Collect and include all relevant output from the tools in your response.\\n3. Analyze the data and provide reasoning to help determine whether the telemetry supports or explains the triggered alert.\\n\\nYour response should include:\\n- Raw data from each tool\\n- A concise summary of findings\\n- Any insights or hypotheses that explain the alert\"), 'maintenance_check': MaintenanceCheckToolConfig(description='Check if a host is under maintenance during the time of an alert to help determine if the alert can be deprioritized.', llm_name='agent_llm', prompt='User will provide you with a system alert represented in JSON format. You know for a fact that there is maintenance happening for the host. Maintenance start time for this host is : [{maintenance_start_str}]; end time is: [{maintenance_end_str}] (end time empty means that there is not yet a set end time for the maintenance on the host)\\nGenerate a markdown report in the following format:\\n\\n## Alert Summary\\n(summary of what happened in the alert JSON data)\\n\\n## Collected Metrics\\n(lay out the maintenance information)\\n\\n## Analysis\\n(Describe the maintenance status of this host)\\n\\n## Recommended Actions\\n(Bullet point list: write how the user may not need to worry about this alert given that the host is under maintenance, and they could check if the issue persists afterward)\\n\\n## Alert Status\\n(can deprioritize the investigation of the alert, host under maintenance)', static_data_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/maintenance_static_dataset.csv', skip_maintenance_check=False), 'categorizer': CategorizerToolConfig(description='This is a categorization tool used at the end of the pipeline.', llm_name='agent_llm', prompt='You will be given a system-generated alert triage report. Your job is to read the report carefully and determine the most likely root cause of the issue. Then, categorize the root cause into one of the following predefined categories:\\n\\n**Valid Categories**\\n- `software`: The alert was triggered due to a malfunctioning or inactive monitoring service (e.g., Telegraf not running).\\n- `network_connectivity`: The host is not reachable via ping or curl, or there are signs of connection issues due to blocked ports, broken services, or firewall rules (e.g., telnet fails).\\n- `hardware`: The alert is caused by a hardware failure or degradation.\\n- `repetitive_behavior`: The alert is triggered by a recurring or periodic behavior pattern (e.g., regular CPU spikes or memory surges).\\n- `false_positive`: No clear signs of failure or degradation; system appears healthy and no suspicious pattern is found.\\n- `need_investigation`: The report contains conflicting, ambiguous, or insufficient information to determine a clear root cause.\\n\\n**Response Format**\\n- Line 1: Output only the category name (e.g., `hardware`)\\n- Line 2: Briefly explain your reasoning based on the contents of the report.\\n- Example response:\\nnetwork_connectivity\\nPing and curl to the host both failed, and telnet to the monitored port timed out, indicating a likely connectivity or firewall issue.\\n\\n**Important Guidelines**\\n- Base your categorization only on evidence presented in the report.\\n- If no category clearly fits, default to `need_investigation`.')} function_groups={} llms={'agent_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.5, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=2048), 'tool_reasoning_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.2, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=2048), 'nim_rag_eval_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/alert_triage_model_selection_output/optimizer'), eval_metrics={'classification_accuracy': OptimizerMetric(evaluator_name='classification_accuracy', direction='maximize', weight=1.0)}, reps_per_param_set=1, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=AlertTriageAgentWorkflowConfig(tool_names=['hardware_check', 'host_performance_check', 'monitoring_process_check', 'network_connectivity_check', 'telemetry_metrics_analysis_agent'], llm_name='agent_llm', offline_mode=True, offline_data_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/offline_data.csv', benign_fallback_data_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/benign_fallback_offline_data.json', agent_prompt='**Role**\\nYou are a Triage Agent responsible for diagnosing and troubleshooting system alerts in real time. Your goal is to determine whether an alert indicates a true issue, identify the root cause, and provide a clear, structured triage report to assist system analysts.\\n\\n\\n**Instructions**\\n\\n1. **Analyze the Alert**\\n   Begin by interpreting the incoming alert. Identify its type (e.g., *InstanceDown*, *HighCPUUsage*) and note any relevant details.\\n\\n2. **Select and Use Diagnostic Tools**\\n   Based on the alert type, choose the most relevant tools to gather system metrics. Use each tool only once per alert.\\n\\n   - `hardware_check`: Retrieves server power status and hardware health via IPMI. Useful for diagnosing instance down alerts or suspected hardware failures.\\n   - `host_performance_check`: Collects system-level CPU and memory usage using commands like `top` and `ps`. Use this to identify host\\'s resource (CPR and memory) usage bottlenecks.\\n   - `monitoring_process_check`: Checks whether critical processes are running on the host. Useful for verifying system functionality during instance down or degraded performance.\\n   - `network_connectivity_check`: Tests host connectivity through ping, telnet, and HTTP health checks. Helps determine if the server is reachable from the network.\\n   - `telemetry_metrics_analysis_agent`: Pulls telemetry metrics to check host status and analyze usage trends. Effective for validating instance uptime and system load over time.\\n\\n   Once you\\'ve received outputs from all selected tools, **pause to analyze them before proceeding further**.\\n\\n3. **Correlate Data and Determine Root Cause**\\n   - Evaluate the retrieved metrics against the alert details.\\n   - Determine if the alert reflects a real problem or is a false positive.\\n   - If an issue is detected, identify likely causes—such as hardware failure, performance bottlenecks, or network issues.\\n\\n4. **Generate a Structured Triage Report (in Markdown format)**\\n   Organize your findings clearly under these sections:\\n\\n   - **Alert Summary**: Brief description of the alert received.\\n   - **Collected Metrics**: Outputs from the diagnostic tools used.\\n   - **Analysis**: Interpretation of the data and how it relates to the alert.\\n   - **Recommended Actions**: Suggested next steps to mitigate or resolve the issue.\\n   - **Alert Status**: Choose one — \"Valid\", \"Abnormal but benign\", or \"False alarm\".\\n\\n\\n**Important Rules**\\n- Do not call the same tool more than once per alert.\\n- Analyze tool outputs before taking any additional action.\\n- Stay concise, structured, and actionable.') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/alert_triage_model_selection_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/offline_data.json'), profiler=None), evaluators={'classification_accuracy': ClassificationEvaluatorConfig(), 'rag_accuracy': RagasEvaluatorConfig(llm_name='nim_rag_eval_llm', metric='AnswerAccuracy', input_obj_field=None)})\n",
      "2025-10-24 10:59:54 - INFO     - nat_alert_triage_agent:104 - Preloaded test data from: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/offline_data.csv\n",
      "2025-10-24 10:59:54 - INFO     - nat_alert_triage_agent:108 - Preloaded benign fallback data from: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/benign_fallback_offline_data.json\n",
      "2025-10-24 10:59:54 - INFO     - nat_alert_triage_agent:80 - ================================================Running in offline mode=================================================\n",
      "Running workflow:   0%|                                   | 0/7 [00:00<?, ?it/s]2025-10-24 10:59:54 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-0.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:59:54 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-1.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:59:54 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-2.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:59:54 - INFO     - nat_alert_triage_agent:258 - Host: [test-instance-3.example.com] is under maintenance according to the maintenance database\n",
      "2025-10-24 10:59:58 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-4.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:59:58 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-5.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:59:58 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-6.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 10:59:58 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  14%|███▊                       | 1/7 [00:03<00:23,  3.91s/it]2025-10-24 11:00:08 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  29%|███████▋                   | 2/7 [00:14<00:38,  7.62s/it]2025-10-24 11:00:12 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  43%|███████████▌               | 3/7 [00:17<00:23,  5.77s/it]2025-10-24 11:00:17 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  57%|███████████████▍           | 4/7 [00:23<00:17,  5.77s/it]2025-10-24 11:00:26 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  71%|███████████████████▎       | 5/7 [00:31<00:13,  6.70s/it]2025-10-24 11:00:55 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  86%|███████████████████████▏   | 6/7 [01:01<00:14, 14.49s/it]2025-10-24 11:01:24 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow: 100%|███████████████████████████| 7/7 [01:29<00:00, 12.80s/it]\n",
      "Evaluating classification accuracy:   0%|                 | 0/7 [00:00<?, ?it/s]\n",
      "Evaluating classification accuracy: 100%|█████████| 7/7 [00:00<00:00, 36.89it/s]\u001b[A\n",
      "2025-10-24 11:01:24 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  14%|██▏            | 1/7 [00:00<00:04,  1.42it/s]\u001b[A2025-10-24 11:01:24 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  57%|████████▌      | 4/7 [00:00<00:00,  5.70it/s]\u001b[A\n",
      "Evaluating Ragas nv_accuracy: 100%|███████████████| 7/7 [00:01<00:00,  4.31it/s]\u001b[A\n",
      "2025-10-24 11:01:25 - INFO     - nat_alert_triage_agent:164 - Cleaning up\n",
      "2025-10-24 11:01:25 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 11:01:25 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/alert_triage_model_selection_output/workflow_output.json\n",
      "2025-10-24 11:01:25 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/alert_triage_model_selection_output/classification_accuracy_output.json\n",
      "2025-10-24 11:01:25 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/alert_triage_model_selection_output/rag_accuracy_output.json\n",
      "\u001b[32m[I 2025-10-24 11:01:25,678]\u001b[0m Trial 1 finished with value: 0.29 and parameters: {'llms.agent_llm.temperature': 0.5, 'llms.agent_llm.model_name': 'meta/llama-3.1-70b-instruct'}. Best is trial 0 with value: 0.29.\u001b[0m\n",
      "2025-10-24 11:01:25 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={'hardware_check': HardwareCheckToolConfig(description='This tool checks hardware health status using IPMI monitoring to detect power state, hardware degradation, and anomalies that could explain alerts. Args: host_id: str', llm_name='tool_reasoning_llm', prompt=\"You are analyzing IPMI metrics to support host monitoring and alert triage. Use the provided IPMI output to assess overall system status. Your goals are to:\\n\\n1. Determine the system's current power state.\\n2. Identify any signs of hardware degradation or failure.\\n3. Flag any anomalies that could explain why a monitoring alert was triggered.\\n\\nReview the data carefully and summarize your assessment in a clear and structured format.\\n\\nIPMI Output:\\n{input_data}\\n\\nFormat your response as follows:\\n\\nPower Status: ON / OFF\\nHardware Health: Normal / Issues Detected\\nObserved Anomalies: [List any irregularities or warning signs]\\nPossible Cause of Alert: [e.g., hardware issue, thermal spike, power fluctuation, no clear issue]\\nNext Steps: [Recommended actions or checks for further triage]\", offline_mode=True), 'host_performance_check': HostPerformanceCheckToolConfig(description='This tool retrieves CPU usage, memory usage, and hardware I/O usage details for a given host. Args: host_id: str', llm_name='tool_reasoning_llm', parsing_prompt='You are given system performance data captured from a host. Your task is to extract and organize the information into a clean, structured JSON format. The input contains system details and performance metrics, such as CPU, memory, and disk I/O.\\n\\nFollow these instructions:\\n\\n1. Identify metric categories dynamically based on the line prefixes or column headers (e.g., \"Mem:\", \"Swap:\", \"CPU:\", \"Device:\").\\n2. For each category, extract the numerical values and map them to meaningful field names.\\n3. Group related fields under sections such as \"memory_usage\", \"swap_usage\", \"cpu_usage\", \"disk_io\", etc.\\n4. Use consistent, readable key names for all fields.\\n5. Return **only** the final JSON object — no explanations or extra text.\\n\\nHere is the input data:\\n{input_data}', analysis_prompt='You are analyzing system metrics to assess CPU and memory usage. Use the output below to determine whether CPU or memory usage is abnormally high, identify which processes are consuming the most resources, and assess whether the usage patterns could explain a recent alert.\\n\\nInstructions:\\n1. Evaluate overall CPU and memory usage levels.\\n2. List the top resource-consuming processes, including their name, PID, %CPU, and %MEM.\\n3. Identify any potential causes of high usage (e.g., memory leak, runaway process, legitimate high load).\\n4. Recommend possible next steps for investigation or mitigation.\\n\\nFormat your response as a structured summary:\\n\\nCPU Usage: Normal / High (X% usage)\\nMemory Usage: Normal / High (X% usage)\\nTop Resource-Consuming Processes: [Process name, PID, %CPU, %MEM]\\nPotential Cause of High Usage: [e.g., runaway process, heavy load, memory leak]\\nNext Steps: [Suggested mitigation actions]\\n\\nSystem Metrics Output:\\n{input_data}\\n', offline_mode=True), 'monitoring_process_check': MonitoringProcessCheckToolConfig(description='This tool checks the status of critical monitoring processes and services on a target host by executing system commands. Args: host_id: str', llm_name='tool_reasoning_llm', prompt='You are checking whether the telegraf service is running on the server. Use the monitoring output below to verify its status. If it’s not running, identify possible reasons and assess the impact.\\n\\nInstructions:\\n1. Check if the telegraf process is present and active.\\n2. Evaluate the potential impact of telegraf not running on system availability or monitoring.\\n3. Identify likely causes for the process not running.\\n\\nFormat your response as a structured summary:\\n* **Telegraf Running:** Yes / No\\n* **Potential Impact:** [e.g., host seems down to the monitoring system, delayed alerting]\\n* **Possible Cause:** [e.g., process crash, misconfiguration, resource constraints]\\n* **Next Steps:** [e.g., restart telegraf, check logs]\\n\\nMonitoring Output:\\n{input_data}', offline_mode=True), 'network_connectivity_check': NetworkConnectivityCheckToolConfig(description='This tool checks network connectivity of a host by running ping and socket connection tests. Args: host_id: str', llm_name='tool_reasoning_llm', prompt='You are assisting with alert triage by checking the network connectivity status of a host. Use the outputs from `ping` and `telnet` commands to determine whether the host is reachable. If connectivity issues are detected, analyze the possible root causes and provide a structured summary of your findings.\\n\\nInstructions:\\n1. Interpret the `ping` and `telnet` results to assess host reachability.\\n2. Determine whether there is a connectivity issue.\\n3. Identify potential causes, such as network failure, firewall restrictions, or service unavailability.\\n4. Recommend appropriate next steps for troubleshooting or escalation.\\n\\nFormat your response as a structured summary:\\n\\nPing Status: Successful / Failed\\nTelnet Status: Connected / Failed\\nPotential Cause of Connectivity Issue: [e.g., network failure, firewall rules, service outage, no issue]\\nNext Steps: [e.g., check network logs, restart network services, escalate issue, or no action needed]\\n\\nPing Output:\\n{ping_data}\\n\\nTelnet Output:\\n{telnet_data}', offline_mode=True), 'telemetry_metrics_host_heartbeat_check': TelemetryMetricsHostHeartbeatCheckToolConfig(description=\"This tool checks if a host's telemetry monitoring service is reporting heartbeat metrics. This tells us if the host is up and running. Args: host_id: str\", llm_name='tool_reasoning_llm', prompt=\"The following is the telemetry metrics fetched for the host to see if it's been up and running (if result is empty, then the monitoring service on the host is down):\\n{data}\\nBased on the data, summarize the fetched data and provide a conclusion of the host's running status.\", offline_mode=True, metrics_url=''), 'telemetry_metrics_host_performance_check': TelemetryMetricsHostPerformanceCheckToolConfig(description='This tool checks the performance of the host by analyzing the CPU usage timeseries. Args: host_id: str', llm_name='tool_reasoning_llm', prompt=\"You are an expert on analyzing CPU usage timeseries. Periodic usage peaks are expected benign system behavior.\\nUser will provide data in the format of a list of lists, where each sublist contains two elements: timestamp and CPU usage percentage. User will also provide statistics on the timeseries. Write a markdown report about what was observed in the timeseries.\\n\\nExample format:\\n# CPU Usage Analysis Report\\nThe data analysis is performed on 14 days of CPU usage percentage data.\\n\\n## Data Statistics\\ndata start and end time, data point interval, CPU usage statistics\\n\\n## Observations\\nany patterns observed? Should be one of the below cases:\\n- Are there any cyclic usage surges?\\n  - What is the cycle?\\n  - What is the high and low CPU usage of the pattern?\\n- Is there one anomalous peak?\\n  - When did it happen?\\n  - What is it like before and after?\\n- No obvious pattern? A mix of patterns? => it's normal flutuation of the system (max usage less than 60%)\\n  - What is the fluctuation range?\\n\\n## Conclusion\\nSummarize the observation.\\nCategories:\\n- peak in the data means the high CPU usage is an anomaly and requires attention\\n- periodic behvior means the high usage is benign\\n- overall moderate (max usage less than 60%) usage means no issue in the system\\n\\n## Pattern Label\\nAnomalous Peak/Periodic Surges/Normal Fluctuations\\n\", offline_mode=True, metrics_url=''), 'telemetry_metrics_analysis_agent': TelemetryMetricsAnalysisAgentConfig(description='This is a telemetry metrics tool used to monitor remotely collected telemetry data. It checks server heartbeat data to determine whether the server is up and running and analyzes CPU usage patterns over the past 14 days to identify potential CPU issues. Args: host_id: str, alert_type: str', tool_names=['telemetry_metrics_host_heartbeat_check', 'telemetry_metrics_host_performance_check'], llm_name='agent_llm', prompt=\"You arg a helpful alert triage assistant. Your task is to investigate an alert that was just triggered on a specific host. You will be given two inputs:\\n- `host_id`: the identifier of the host where the alert occurred.\\n- `alert_type`: the type of alert that triggered.\\n\\nUse the tools provided below to collect relevant telemetry data for the specified host:\\n\\nTools:\\n- `telemetry_metrics_host_heartbeat_check`: Use this to check the server's heartbeat and determine if the host is currently up and responsive.\\n- `telemetry_metrics_host_performance_check`: Use this to analyze CPU usage trends over the past 14 days and identify abnormal patterns.\\n\\nInstructions:\\n1. Run the appropriate tools based on the host and alert type.\\n2. Collect and include all relevant output from the tools in your response.\\n3. Analyze the data and provide reasoning to help determine whether the telemetry supports or explains the triggered alert.\\n\\nYour response should include:\\n- Raw data from each tool\\n- A concise summary of findings\\n- Any insights or hypotheses that explain the alert\"), 'maintenance_check': MaintenanceCheckToolConfig(description='Check if a host is under maintenance during the time of an alert to help determine if the alert can be deprioritized.', llm_name='agent_llm', prompt='User will provide you with a system alert represented in JSON format. You know for a fact that there is maintenance happening for the host. Maintenance start time for this host is : [{maintenance_start_str}]; end time is: [{maintenance_end_str}] (end time empty means that there is not yet a set end time for the maintenance on the host)\\nGenerate a markdown report in the following format:\\n\\n## Alert Summary\\n(summary of what happened in the alert JSON data)\\n\\n## Collected Metrics\\n(lay out the maintenance information)\\n\\n## Analysis\\n(Describe the maintenance status of this host)\\n\\n## Recommended Actions\\n(Bullet point list: write how the user may not need to worry about this alert given that the host is under maintenance, and they could check if the issue persists afterward)\\n\\n## Alert Status\\n(can deprioritize the investigation of the alert, host under maintenance)', static_data_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/maintenance_static_dataset.csv', skip_maintenance_check=False), 'categorizer': CategorizerToolConfig(description='This is a categorization tool used at the end of the pipeline.', llm_name='agent_llm', prompt='You will be given a system-generated alert triage report. Your job is to read the report carefully and determine the most likely root cause of the issue. Then, categorize the root cause into one of the following predefined categories:\\n\\n**Valid Categories**\\n- `software`: The alert was triggered due to a malfunctioning or inactive monitoring service (e.g., Telegraf not running).\\n- `network_connectivity`: The host is not reachable via ping or curl, or there are signs of connection issues due to blocked ports, broken services, or firewall rules (e.g., telnet fails).\\n- `hardware`: The alert is caused by a hardware failure or degradation.\\n- `repetitive_behavior`: The alert is triggered by a recurring or periodic behavior pattern (e.g., regular CPU spikes or memory surges).\\n- `false_positive`: No clear signs of failure or degradation; system appears healthy and no suspicious pattern is found.\\n- `need_investigation`: The report contains conflicting, ambiguous, or insufficient information to determine a clear root cause.\\n\\n**Response Format**\\n- Line 1: Output only the category name (e.g., `hardware`)\\n- Line 2: Briefly explain your reasoning based on the contents of the report.\\n- Example response:\\nnetwork_connectivity\\nPing and curl to the host both failed, and telnet to the monitored port timed out, indicating a likely connectivity or firewall issue.\\n\\n**Important Guidelines**\\n- Base your categorization only on evidence presented in the report.\\n- If no category clearly fits, default to `need_investigation`.')} function_groups={} llms={'agent_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.5, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=2048), 'tool_reasoning_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.2, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=2048), 'nim_rag_eval_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/alert_triage_model_selection_output/optimizer'), eval_metrics={'classification_accuracy': OptimizerMetric(evaluator_name='classification_accuracy', direction='maximize', weight=1.0)}, reps_per_param_set=1, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=AlertTriageAgentWorkflowConfig(tool_names=['hardware_check', 'host_performance_check', 'monitoring_process_check', 'network_connectivity_check', 'telemetry_metrics_analysis_agent'], llm_name='agent_llm', offline_mode=True, offline_data_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/offline_data.csv', benign_fallback_data_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/benign_fallback_offline_data.json', agent_prompt='**Role**\\nYou are a Triage Agent responsible for diagnosing and troubleshooting system alerts in real time. Your goal is to determine whether an alert indicates a true issue, identify the root cause, and provide a clear, structured triage report to assist system analysts.\\n\\n\\n**Instructions**\\n\\n1. **Analyze the Alert**\\n   Begin by interpreting the incoming alert. Identify its type (e.g., *InstanceDown*, *HighCPUUsage*) and note any relevant details.\\n\\n2. **Select and Use Diagnostic Tools**\\n   Based on the alert type, choose the most relevant tools to gather system metrics. Use each tool only once per alert.\\n\\n   - `hardware_check`: Retrieves server power status and hardware health via IPMI. Useful for diagnosing instance down alerts or suspected hardware failures.\\n   - `host_performance_check`: Collects system-level CPU and memory usage using commands like `top` and `ps`. Use this to identify host\\'s resource (CPR and memory) usage bottlenecks.\\n   - `monitoring_process_check`: Checks whether critical processes are running on the host. Useful for verifying system functionality during instance down or degraded performance.\\n   - `network_connectivity_check`: Tests host connectivity through ping, telnet, and HTTP health checks. Helps determine if the server is reachable from the network.\\n   - `telemetry_metrics_analysis_agent`: Pulls telemetry metrics to check host status and analyze usage trends. Effective for validating instance uptime and system load over time.\\n\\n   Once you\\'ve received outputs from all selected tools, **pause to analyze them before proceeding further**.\\n\\n3. **Correlate Data and Determine Root Cause**\\n   - Evaluate the retrieved metrics against the alert details.\\n   - Determine if the alert reflects a real problem or is a false positive.\\n   - If an issue is detected, identify likely causes—such as hardware failure, performance bottlenecks, or network issues.\\n\\n4. **Generate a Structured Triage Report (in Markdown format)**\\n   Organize your findings clearly under these sections:\\n\\n   - **Alert Summary**: Brief description of the alert received.\\n   - **Collected Metrics**: Outputs from the diagnostic tools used.\\n   - **Analysis**: Interpretation of the data and how it relates to the alert.\\n   - **Recommended Actions**: Suggested next steps to mitigate or resolve the issue.\\n   - **Alert Status**: Choose one — \"Valid\", \"Abnormal but benign\", or \"False alarm\".\\n\\n\\n**Important Rules**\\n- Do not call the same tool more than once per alert.\\n- Analyze tool outputs before taking any additional action.\\n- Stay concise, structured, and actionable.') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/alert_triage_model_selection_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/offline_data.json'), profiler=None), evaluators={'classification_accuracy': ClassificationEvaluatorConfig(), 'rag_accuracy': RagasEvaluatorConfig(llm_name='nim_rag_eval_llm', metric='AnswerAccuracy', input_obj_field=None)})\n",
      "2025-10-24 11:01:25 - INFO     - nat_alert_triage_agent:104 - Preloaded test data from: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/offline_data.csv\n",
      "2025-10-24 11:01:25 - INFO     - nat_alert_triage_agent:108 - Preloaded benign fallback data from: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/benign_fallback_offline_data.json\n",
      "2025-10-24 11:01:25 - INFO     - nat_alert_triage_agent:80 - ================================================Running in offline mode=================================================\n",
      "Running workflow:   0%|                                   | 0/7 [00:00<?, ?it/s]2025-10-24 11:01:25 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-0.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 11:01:25 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-1.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 11:01:25 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-2.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 11:01:25 - INFO     - nat_alert_triage_agent:258 - Host: [test-instance-3.example.com] is under maintenance according to the maintenance database\n",
      "2025-10-24 11:01:28 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-4.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 11:01:28 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-5.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 11:01:28 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-6.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 11:01:28 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  14%|███▊                       | 1/7 [00:02<00:14,  2.40s/it]2025-10-24 11:02:41 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  29%|███████▋                   | 2/7 [01:15<03:40, 44.10s/it]2025-10-24 11:02:54 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  43%|███████████▌               | 3/7 [01:29<02:00, 30.06s/it]2025-10-24 11:03:02 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  57%|███████████████▍           | 4/7 [01:36<01:03, 21.27s/it]2025-10-24 11:03:56 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  71%|███████████████████▎       | 5/7 [02:30<01:05, 32.93s/it]2025-10-24 11:04:12 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  86%|███████████████████████▏   | 6/7 [02:47<00:27, 27.44s/it]2025-10-24 11:04:44 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow: 100%|███████████████████████████| 7/7 [03:18<00:00, 28.42s/it]\n",
      "Evaluating classification accuracy:   0%|                 | 0/7 [00:00<?, ?it/s]\n",
      "Evaluating classification accuracy: 100%|█████████| 7/7 [00:00<00:00, 34.76it/s]\u001b[A\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  14%|██▏            | 1/7 [00:00<00:05,  1.15it/s]\u001b[A2025-10-24 11:04:45 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  29%|████▎          | 2/7 [00:00<00:02,  2.33it/s]\u001b[A\n",
      "Evaluating Ragas nv_accuracy: 100%|███████████████| 7/7 [00:01<00:00,  4.08it/s]\u001b[A\n",
      "2025-10-24 11:04:46 - INFO     - nat_alert_triage_agent:164 - Cleaning up\n",
      "2025-10-24 11:04:46 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 11:04:46 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/alert_triage_model_selection_output/workflow_output.json\n",
      "2025-10-24 11:04:46 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/alert_triage_model_selection_output/classification_accuracy_output.json\n",
      "2025-10-24 11:04:46 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/alert_triage_model_selection_output/rag_accuracy_output.json\n",
      "\u001b[32m[I 2025-10-24 11:04:46,415]\u001b[0m Trial 2 finished with value: 0.43 and parameters: {'llms.agent_llm.temperature': 0.5, 'llms.agent_llm.model_name': 'meta/llama-3.1-8b-instruct'}. Best is trial 2 with value: 0.43.\u001b[0m\n",
      "2025-10-24 11:04:46 - INFO     - nat.eval.evaluate:448 - Starting evaluation run with config file: general=GeneralConfig(use_uvloop=None, telemetry=TelemetryConfig(logging={}, tracing={}), front_end=FastApiFrontEndConfig(root_path='', host='localhost', port=8000, reload=False, workers=1, scheduler_address=None, db_url=None, max_running_async_jobs=10, dask_log_level='WARNING', step_adaptor=StepAdaptorConfig(mode=<StepAdaptorMode.DEFAULT: 'default'>, custom_event_types=[]), workflow=EndpointBase(method='POST', description='Executes the default NAT workflow from the loaded configuration ', path='/generate', websocket_path='/websocket', openai_api_path='/chat', openai_api_v1_path='/v1/chat/completions'), evaluate=EndpointBase(method='POST', description='Evaluates the performance and accuracy of the workflow on a dataset', path='/evaluate', websocket_path=None, openai_api_path=None, openai_api_v1_path=None), oauth2_callback_path='/auth/redirect', endpoints=[], cors=CrossOriginResourceSharing(allow_origins=None, allow_origin_regex=None, allow_methods=['GET'], allow_headers=[], allow_credentials=False, expose_headers=[], max_age=600), use_gunicorn=False, runner_class=None, object_store=None)) functions={'hardware_check': HardwareCheckToolConfig(description='This tool checks hardware health status using IPMI monitoring to detect power state, hardware degradation, and anomalies that could explain alerts. Args: host_id: str', llm_name='tool_reasoning_llm', prompt=\"You are analyzing IPMI metrics to support host monitoring and alert triage. Use the provided IPMI output to assess overall system status. Your goals are to:\\n\\n1. Determine the system's current power state.\\n2. Identify any signs of hardware degradation or failure.\\n3. Flag any anomalies that could explain why a monitoring alert was triggered.\\n\\nReview the data carefully and summarize your assessment in a clear and structured format.\\n\\nIPMI Output:\\n{input_data}\\n\\nFormat your response as follows:\\n\\nPower Status: ON / OFF\\nHardware Health: Normal / Issues Detected\\nObserved Anomalies: [List any irregularities or warning signs]\\nPossible Cause of Alert: [e.g., hardware issue, thermal spike, power fluctuation, no clear issue]\\nNext Steps: [Recommended actions or checks for further triage]\", offline_mode=True), 'host_performance_check': HostPerformanceCheckToolConfig(description='This tool retrieves CPU usage, memory usage, and hardware I/O usage details for a given host. Args: host_id: str', llm_name='tool_reasoning_llm', parsing_prompt='You are given system performance data captured from a host. Your task is to extract and organize the information into a clean, structured JSON format. The input contains system details and performance metrics, such as CPU, memory, and disk I/O.\\n\\nFollow these instructions:\\n\\n1. Identify metric categories dynamically based on the line prefixes or column headers (e.g., \"Mem:\", \"Swap:\", \"CPU:\", \"Device:\").\\n2. For each category, extract the numerical values and map them to meaningful field names.\\n3. Group related fields under sections such as \"memory_usage\", \"swap_usage\", \"cpu_usage\", \"disk_io\", etc.\\n4. Use consistent, readable key names for all fields.\\n5. Return **only** the final JSON object — no explanations or extra text.\\n\\nHere is the input data:\\n{input_data}', analysis_prompt='You are analyzing system metrics to assess CPU and memory usage. Use the output below to determine whether CPU or memory usage is abnormally high, identify which processes are consuming the most resources, and assess whether the usage patterns could explain a recent alert.\\n\\nInstructions:\\n1. Evaluate overall CPU and memory usage levels.\\n2. List the top resource-consuming processes, including their name, PID, %CPU, and %MEM.\\n3. Identify any potential causes of high usage (e.g., memory leak, runaway process, legitimate high load).\\n4. Recommend possible next steps for investigation or mitigation.\\n\\nFormat your response as a structured summary:\\n\\nCPU Usage: Normal / High (X% usage)\\nMemory Usage: Normal / High (X% usage)\\nTop Resource-Consuming Processes: [Process name, PID, %CPU, %MEM]\\nPotential Cause of High Usage: [e.g., runaway process, heavy load, memory leak]\\nNext Steps: [Suggested mitigation actions]\\n\\nSystem Metrics Output:\\n{input_data}\\n', offline_mode=True), 'monitoring_process_check': MonitoringProcessCheckToolConfig(description='This tool checks the status of critical monitoring processes and services on a target host by executing system commands. Args: host_id: str', llm_name='tool_reasoning_llm', prompt='You are checking whether the telegraf service is running on the server. Use the monitoring output below to verify its status. If it’s not running, identify possible reasons and assess the impact.\\n\\nInstructions:\\n1. Check if the telegraf process is present and active.\\n2. Evaluate the potential impact of telegraf not running on system availability or monitoring.\\n3. Identify likely causes for the process not running.\\n\\nFormat your response as a structured summary:\\n* **Telegraf Running:** Yes / No\\n* **Potential Impact:** [e.g., host seems down to the monitoring system, delayed alerting]\\n* **Possible Cause:** [e.g., process crash, misconfiguration, resource constraints]\\n* **Next Steps:** [e.g., restart telegraf, check logs]\\n\\nMonitoring Output:\\n{input_data}', offline_mode=True), 'network_connectivity_check': NetworkConnectivityCheckToolConfig(description='This tool checks network connectivity of a host by running ping and socket connection tests. Args: host_id: str', llm_name='tool_reasoning_llm', prompt='You are assisting with alert triage by checking the network connectivity status of a host. Use the outputs from `ping` and `telnet` commands to determine whether the host is reachable. If connectivity issues are detected, analyze the possible root causes and provide a structured summary of your findings.\\n\\nInstructions:\\n1. Interpret the `ping` and `telnet` results to assess host reachability.\\n2. Determine whether there is a connectivity issue.\\n3. Identify potential causes, such as network failure, firewall restrictions, or service unavailability.\\n4. Recommend appropriate next steps for troubleshooting or escalation.\\n\\nFormat your response as a structured summary:\\n\\nPing Status: Successful / Failed\\nTelnet Status: Connected / Failed\\nPotential Cause of Connectivity Issue: [e.g., network failure, firewall rules, service outage, no issue]\\nNext Steps: [e.g., check network logs, restart network services, escalate issue, or no action needed]\\n\\nPing Output:\\n{ping_data}\\n\\nTelnet Output:\\n{telnet_data}', offline_mode=True), 'telemetry_metrics_host_heartbeat_check': TelemetryMetricsHostHeartbeatCheckToolConfig(description=\"This tool checks if a host's telemetry monitoring service is reporting heartbeat metrics. This tells us if the host is up and running. Args: host_id: str\", llm_name='tool_reasoning_llm', prompt=\"The following is the telemetry metrics fetched for the host to see if it's been up and running (if result is empty, then the monitoring service on the host is down):\\n{data}\\nBased on the data, summarize the fetched data and provide a conclusion of the host's running status.\", offline_mode=True, metrics_url=''), 'telemetry_metrics_host_performance_check': TelemetryMetricsHostPerformanceCheckToolConfig(description='This tool checks the performance of the host by analyzing the CPU usage timeseries. Args: host_id: str', llm_name='tool_reasoning_llm', prompt=\"You are an expert on analyzing CPU usage timeseries. Periodic usage peaks are expected benign system behavior.\\nUser will provide data in the format of a list of lists, where each sublist contains two elements: timestamp and CPU usage percentage. User will also provide statistics on the timeseries. Write a markdown report about what was observed in the timeseries.\\n\\nExample format:\\n# CPU Usage Analysis Report\\nThe data analysis is performed on 14 days of CPU usage percentage data.\\n\\n## Data Statistics\\ndata start and end time, data point interval, CPU usage statistics\\n\\n## Observations\\nany patterns observed? Should be one of the below cases:\\n- Are there any cyclic usage surges?\\n  - What is the cycle?\\n  - What is the high and low CPU usage of the pattern?\\n- Is there one anomalous peak?\\n  - When did it happen?\\n  - What is it like before and after?\\n- No obvious pattern? A mix of patterns? => it's normal flutuation of the system (max usage less than 60%)\\n  - What is the fluctuation range?\\n\\n## Conclusion\\nSummarize the observation.\\nCategories:\\n- peak in the data means the high CPU usage is an anomaly and requires attention\\n- periodic behvior means the high usage is benign\\n- overall moderate (max usage less than 60%) usage means no issue in the system\\n\\n## Pattern Label\\nAnomalous Peak/Periodic Surges/Normal Fluctuations\\n\", offline_mode=True, metrics_url=''), 'telemetry_metrics_analysis_agent': TelemetryMetricsAnalysisAgentConfig(description='This is a telemetry metrics tool used to monitor remotely collected telemetry data. It checks server heartbeat data to determine whether the server is up and running and analyzes CPU usage patterns over the past 14 days to identify potential CPU issues. Args: host_id: str, alert_type: str', tool_names=['telemetry_metrics_host_heartbeat_check', 'telemetry_metrics_host_performance_check'], llm_name='agent_llm', prompt=\"You arg a helpful alert triage assistant. Your task is to investigate an alert that was just triggered on a specific host. You will be given two inputs:\\n- `host_id`: the identifier of the host where the alert occurred.\\n- `alert_type`: the type of alert that triggered.\\n\\nUse the tools provided below to collect relevant telemetry data for the specified host:\\n\\nTools:\\n- `telemetry_metrics_host_heartbeat_check`: Use this to check the server's heartbeat and determine if the host is currently up and responsive.\\n- `telemetry_metrics_host_performance_check`: Use this to analyze CPU usage trends over the past 14 days and identify abnormal patterns.\\n\\nInstructions:\\n1. Run the appropriate tools based on the host and alert type.\\n2. Collect and include all relevant output from the tools in your response.\\n3. Analyze the data and provide reasoning to help determine whether the telemetry supports or explains the triggered alert.\\n\\nYour response should include:\\n- Raw data from each tool\\n- A concise summary of findings\\n- Any insights or hypotheses that explain the alert\"), 'maintenance_check': MaintenanceCheckToolConfig(description='Check if a host is under maintenance during the time of an alert to help determine if the alert can be deprioritized.', llm_name='agent_llm', prompt='User will provide you with a system alert represented in JSON format. You know for a fact that there is maintenance happening for the host. Maintenance start time for this host is : [{maintenance_start_str}]; end time is: [{maintenance_end_str}] (end time empty means that there is not yet a set end time for the maintenance on the host)\\nGenerate a markdown report in the following format:\\n\\n## Alert Summary\\n(summary of what happened in the alert JSON data)\\n\\n## Collected Metrics\\n(lay out the maintenance information)\\n\\n## Analysis\\n(Describe the maintenance status of this host)\\n\\n## Recommended Actions\\n(Bullet point list: write how the user may not need to worry about this alert given that the host is under maintenance, and they could check if the issue persists afterward)\\n\\n## Alert Status\\n(can deprioritize the investigation of the alert, host under maintenance)', static_data_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/maintenance_static_dataset.csv', skip_maintenance_check=False), 'categorizer': CategorizerToolConfig(description='This is a categorization tool used at the end of the pipeline.', llm_name='agent_llm', prompt='You will be given a system-generated alert triage report. Your job is to read the report carefully and determine the most likely root cause of the issue. Then, categorize the root cause into one of the following predefined categories:\\n\\n**Valid Categories**\\n- `software`: The alert was triggered due to a malfunctioning or inactive monitoring service (e.g., Telegraf not running).\\n- `network_connectivity`: The host is not reachable via ping or curl, or there are signs of connection issues due to blocked ports, broken services, or firewall rules (e.g., telnet fails).\\n- `hardware`: The alert is caused by a hardware failure or degradation.\\n- `repetitive_behavior`: The alert is triggered by a recurring or periodic behavior pattern (e.g., regular CPU spikes or memory surges).\\n- `false_positive`: No clear signs of failure or degradation; system appears healthy and no suspicious pattern is found.\\n- `need_investigation`: The report contains conflicting, ambiguous, or insufficient information to determine a clear root cause.\\n\\n**Response Format**\\n- Line 1: Output only the category name (e.g., `hardware`)\\n- Line 2: Briefly explain your reasoning based on the contents of the report.\\n- Example response:\\nnetwork_connectivity\\nPing and curl to the host both failed, and telnet to the monitored port timed out, indicating a likely connectivity or firewall issue.\\n\\n**Important Guidelines**\\n- Base your categorization only on evidence presented in the report.\\n- If no category clearly fits, default to `need_investigation`.')} function_groups={} llms={'agent_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-8b-instruct', max_tokens=2048), 'tool_reasoning_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.2, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=2048), 'nim_rag_eval_llm': NIMModelConfig(thinking=None, top_p=1.0, temperature=0.0, optimizable_params=[], search_space={}, do_auto_retry=True, num_retries=5, retry_on_status_codes=[429, 500, 502, 503, 504], retry_on_errors=['Too Many Requests'], api_type=<APITypeEnum.CHAT_COMPLETION: 'chat_completion'>, api_key=None, base_url=None, model_name='meta/llama-3.1-70b-instruct', max_tokens=8)} embedders={} memory={} object_stores={} optimizer=OptimizerConfig(output_path=PosixPath('tmp_workflow/alert_triage_model_selection_output/optimizer'), eval_metrics={'classification_accuracy': OptimizerMetric(evaluator_name='classification_accuracy', direction='maximize', weight=1.0)}, reps_per_param_set=1, target=None, multi_objective_combination_mode='harmonic', numeric=NumericOptimizationConfig(enabled=True, n_trials=20, sampler=<SamplerType.GRID: 'grid'>), prompt=PromptGAOptimizationConfig(enabled=False, prompt_population_init_function=None, prompt_recombination_function=None, ga_population_size=24, ga_generations=15, ga_offspring_size=None, ga_crossover_rate=0.8, ga_mutation_rate=0.3, ga_elitism=2, ga_selection_method='tournament', ga_tournament_size=3, ga_parallel_evaluations=8, ga_diversity_lambda=0.0)) retrievers={} ttc_strategies={} workflow=AlertTriageAgentWorkflowConfig(tool_names=['hardware_check', 'host_performance_check', 'monitoring_process_check', 'network_connectivity_check', 'telemetry_metrics_analysis_agent'], llm_name='agent_llm', offline_mode=True, offline_data_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/offline_data.csv', benign_fallback_data_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/benign_fallback_offline_data.json', agent_prompt='**Role**\\nYou are a Triage Agent responsible for diagnosing and troubleshooting system alerts in real time. Your goal is to determine whether an alert indicates a true issue, identify the root cause, and provide a clear, structured triage report to assist system analysts.\\n\\n\\n**Instructions**\\n\\n1. **Analyze the Alert**\\n   Begin by interpreting the incoming alert. Identify its type (e.g., *InstanceDown*, *HighCPUUsage*) and note any relevant details.\\n\\n2. **Select and Use Diagnostic Tools**\\n   Based on the alert type, choose the most relevant tools to gather system metrics. Use each tool only once per alert.\\n\\n   - `hardware_check`: Retrieves server power status and hardware health via IPMI. Useful for diagnosing instance down alerts or suspected hardware failures.\\n   - `host_performance_check`: Collects system-level CPU and memory usage using commands like `top` and `ps`. Use this to identify host\\'s resource (CPR and memory) usage bottlenecks.\\n   - `monitoring_process_check`: Checks whether critical processes are running on the host. Useful for verifying system functionality during instance down or degraded performance.\\n   - `network_connectivity_check`: Tests host connectivity through ping, telnet, and HTTP health checks. Helps determine if the server is reachable from the network.\\n   - `telemetry_metrics_analysis_agent`: Pulls telemetry metrics to check host status and analyze usage trends. Effective for validating instance uptime and system load over time.\\n\\n   Once you\\'ve received outputs from all selected tools, **pause to analyze them before proceeding further**.\\n\\n3. **Correlate Data and Determine Root Cause**\\n   - Evaluate the retrieved metrics against the alert details.\\n   - Determine if the alert reflects a real problem or is a false positive.\\n   - If an issue is detected, identify likely causes—such as hardware failure, performance bottlenecks, or network issues.\\n\\n4. **Generate a Structured Triage Report (in Markdown format)**\\n   Organize your findings clearly under these sections:\\n\\n   - **Alert Summary**: Brief description of the alert received.\\n   - **Collected Metrics**: Outputs from the diagnostic tools used.\\n   - **Analysis**: Interpretation of the data and how it relates to the alert.\\n   - **Recommended Actions**: Suggested next steps to mitigate or resolve the issue.\\n   - **Alert Status**: Choose one — \"Valid\", \"Abnormal but benign\", or \"False alarm\".\\n\\n\\n**Important Rules**\\n- Do not call the same tool more than once per alert.\\n- Analyze tool outputs before taking any additional action.\\n- Stay concise, structured, and actionable.') authentication={} eval=EvalConfig(general=EvalGeneralConfig(max_concurrency=8, workflow_alias=None, output_dir=PosixPath('tmp_workflow/alert_triage_model_selection_output'), output=None, dataset=EvalDatasetJsonConfig(id_key='id', structure=EvalDatasetStructureConfig(disable=False, question_key='question', answer_key='answer', generated_answer_key='generated_answer', trajectory_key='intermediate_steps', expected_trajectory_key='expected_intermediate_steps'), filter=EvalFilterConfig(allowlist=None, denylist=None), s3=None, remote_file_path=None, file_path='/Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/offline_data.json'), profiler=None), evaluators={'classification_accuracy': ClassificationEvaluatorConfig(), 'rag_accuracy': RagasEvaluatorConfig(llm_name='nim_rag_eval_llm', metric='AnswerAccuracy', input_obj_field=None)})\n",
      "2025-10-24 11:04:46 - INFO     - nat_alert_triage_agent:104 - Preloaded test data from: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/offline_data.csv\n",
      "2025-10-24 11:04:46 - INFO     - nat_alert_triage_agent:108 - Preloaded benign fallback data from: /Users/bbednarski/Projects/nat-getting-started-fork/NeMo-Agent-Toolkit/examples/advanced_agents/alert_triage_agent/src/nat_alert_triage_agent/data/benign_fallback_offline_data.json\n",
      "2025-10-24 11:04:46 - INFO     - nat_alert_triage_agent:80 - ================================================Running in offline mode=================================================\n",
      "Running workflow:   0%|                                   | 0/7 [00:00<?, ?it/s]2025-10-24 11:04:46 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-0.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 11:04:46 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-1.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 11:04:46 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-2.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 11:04:46 - INFO     - nat_alert_triage_agent:258 - Host: [test-instance-3.example.com] is under maintenance according to the maintenance database\n",
      "2025-10-24 11:04:49 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-4.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 11:04:49 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-5.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 11:04:49 - INFO     - nat_alert_triage_agent:246 - Host: [test-instance-6.example.com] is NOT under maintenance according to the maintenance database\n",
      "2025-10-24 11:04:49 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  14%|███▊                       | 1/7 [00:03<00:18,  3.08s/it]2025-10-24 11:05:58 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  29%|███████▋                   | 2/7 [01:12<03:30, 42.05s/it]2025-10-24 11:06:21 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  43%|███████████▌               | 3/7 [01:34<02:12, 33.15s/it]2025-10-24 11:06:49 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  57%|███████████████▍           | 4/7 [02:03<01:33, 31.25s/it]2025-10-24 11:07:27 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  71%|███████████████████▎       | 5/7 [02:40<01:06, 33.47s/it]2025-10-24 11:08:05 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow:  86%|███████████████████████▏   | 6/7 [03:18<00:35, 35.01s/it]2025-10-24 11:09:24 - INFO     - nat_alert_triage_agent:150 - Finished agent execution\n",
      "Running workflow: 100%|███████████████████████████| 7/7 [04:37<00:00, 39.71s/it]\n",
      "Evaluating classification accuracy:   0%|                 | 0/7 [00:00<?, ?it/s]\n",
      "Evaluating classification accuracy: 100%|█████████| 7/7 [00:00<00:00, 30.17it/s]\u001b[A\n",
      "2025-10-24 11:09:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  14%|██▏            | 1/7 [00:00<00:04,  1.21it/s]\u001b[A2025-10-24 11:09:25 - WARNING  - ragas.metrics._nv_metrics:157 - An error occurred: [429] Too Many Requests\n",
      "{'status': 429, 'title': 'Too Many Requests'}. Skipping a sample by assigning it nan score.\n",
      "\n",
      "Evaluating Ragas nv_accuracy:  57%|████████▌      | 4/7 [00:00<00:00,  4.97it/s]\u001b[A\n",
      "Evaluating Ragas nv_accuracy: 100%|███████████████| 7/7 [00:01<00:00,  3.94it/s]\u001b[A\n",
      "2025-10-24 11:09:26 - INFO     - nat_alert_triage_agent:164 - Cleaning up\n",
      "2025-10-24 11:09:26 - INFO     - nat.eval.evaluate:252 - Profiler is not enabled. Skipping profiling.\n",
      "2025-10-24 11:09:26 - INFO     - nat.eval.evaluate:337 - Workflow output written to tmp_workflow/alert_triage_model_selection_output/workflow_output.json\n",
      "2025-10-24 11:09:26 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/alert_triage_model_selection_output/classification_accuracy_output.json\n",
      "2025-10-24 11:09:26 - INFO     - nat.eval.evaluate:348 - Evaluation results written to tmp_workflow/alert_triage_model_selection_output/rag_accuracy_output.json\n",
      "\u001b[32m[I 2025-10-24 11:09:26,212]\u001b[0m Trial 3 finished with value: 0.43 and parameters: {'llms.agent_llm.temperature': 0.0, 'llms.agent_llm.model_name': 'meta/llama-3.1-8b-instruct'}. Best is trial 2 with value: 0.43.\u001b[0m\n",
      "2025-10-24 11:09:26 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:127 - Numeric optimization finished\n",
      "2025-10-24 11:09:26 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:173 - Generating Pareto front visualizations...\n",
      "2025-10-24 11:09:26 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:408 - Creating Pareto front visualizations...\n",
      "2025-10-24 11:09:26 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:409 - Total trials: 4\n",
      "2025-10-24 11:09:26 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:410 - Pareto optimal trials: 2\n",
      "2025-10-24 11:09:26 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:438 - Visualization complete!\n",
      "2025-10-24 11:09:26 - INFO     - nat.profiler.parameter_optimization.pareto_visualizer:440 - Plots saved to: tmp_workflow/alert_triage_model_selection_output/optimizer/plots\n",
      "2025-10-24 11:09:26 - INFO     - nat.profiler.parameter_optimization.parameter_optimizer:182 - Pareto visualizations saved to: tmp_workflow/alert_triage_model_selection_output/optimizer/plots\n",
      "2025-10-24 11:09:26 - INFO     - nat.profiler.parameter_optimization.optimizer_runtime:66 - All optimization phases complete.\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!nat optimize --config_file tmp_workflow/configs/alert_triage_config_model_selection.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd59bb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Optimization Results\n",
      "================================================================================\n",
      "\n",
      "Trials Summary:\n",
      " number  value             datetime_start          datetime_complete               duration params_llms.agent_llm.model_name  params_llms.agent_llm.temperature rep_scores  system_attrs_grid_id                                                                                                              system_attrs_search_space    state  pareto_optimal\n",
      "      0   0.29 2025-10-24 10:58:18.680960 2025-10-24 10:59:54.207607 0 days 00:01:35.526647      meta/llama-3.1-70b-instruct                                0.0   [[0.29]]                     0 {'llms.agent_llm.model_name': ['meta/llama-3.1-8b-instruct', 'meta/llama-3.1-70b-instruct'], 'llms.agent_llm.temperature': [0.0, 0.5]} COMPLETE           False\n",
      "      1   0.29 2025-10-24 10:59:54.207769 2025-10-24 11:01:25.678329 0 days 00:01:31.470560      meta/llama-3.1-70b-instruct                                0.5   [[0.29]]                     1 {'llms.agent_llm.model_name': ['meta/llama-3.1-8b-instruct', 'meta/llama-3.1-70b-instruct'], 'llms.agent_llm.temperature': [0.0, 0.5]} COMPLETE           False\n",
      "      2   0.43 2025-10-24 11:01:25.678511 2025-10-24 11:04:46.415370 0 days 00:03:20.736859       meta/llama-3.1-8b-instruct                                0.5   [[0.43]]                     2 {'llms.agent_llm.model_name': ['meta/llama-3.1-8b-instruct', 'meta/llama-3.1-70b-instruct'], 'llms.agent_llm.temperature': [0.0, 0.5]} COMPLETE            True\n",
      "      3   0.43 2025-10-24 11:04:46.415499 2025-10-24 11:09:26.212101 0 days 00:04:39.796602       meta/llama-3.1-8b-instruct                                0.0   [[0.43]]                     3 {'llms.agent_llm.model_name': ['meta/llama-3.1-8b-instruct', 'meta/llama-3.1-70b-instruct'], 'llms.agent_llm.temperature': [0.0, 0.5]} COMPLETE            True\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the optimizer results\n",
    "trials_df_path = Path(\"tmp_workflow/alert_triage_model_selection_output/optimizer/trials_dataframe_params.csv\")\n",
    "\n",
    "if trials_df_path.exists():\n",
    "    trials_df = pd.read_csv(trials_df_path)\n",
    "\n",
    "    print(\"Grid Search Optimization Results\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nTrials Summary:\")\n",
    "    print(trials_df.to_string(index=False))\n",
    "    print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67550b0",
   "metadata": {},
   "source": [
    "<a id=\"eval-triage-agent2\"></a>\n",
    "## 2.6) Re-evaluate the optimized tool-calling agent\n",
    "\n",
    "After completing the `nat optimize` run above, a new file with the optimal parameters from the search have been serialized and saved to `'./tmp_workflow/alert_triage_model_selection_output/optimizer/optimized_config.yml`.\n",
    "\n",
    "<div style=\"color: red; font-style: italic;\">\n",
    "<strong>Note:</strong> Performance of the optimized model may vary due to size of prior search space and number of evaluation trials.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506ef10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path-check-skip-next-line\n",
    "!nat eval --config_file ./tmp_workflow/alert_triage_model_selection_output/optimizer/optimized_config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a10743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load and display classification accuracy results\n",
    "# path-check-skip-next-line\n",
    "with open('./tmp_workflow/alert_triage_model_selection_output/classification_accuracy_output.json') as f:\n",
    "    classification_results = json.load(f)\n",
    "\n",
    "print(\"Classification Accuracy Results:\")\n",
    "print(f\"Average Score: {classification_results['average_score']:.2%}\")\n",
    "print(\"\\nPer-Alert Results:\")\n",
    "for item in classification_results['eval_output_items']:\n",
    "    print(f\"  Alert {item['id']}: Score={item['score']:.2f} - {item['reasoning']}\")\n",
    "\n",
    "# Load and display RAG accuracy results\n",
    "# path-check-skip-next-line\n",
    "with open('./tmp_workflow/alert_triage_model_selection_output/rag_accuracy_output.json') as f:\n",
    "    rag_results = json.load(f)\n",
    "\n",
    "print(\"\\n\\nRAG Accuracy Results:\")\n",
    "print(f\"Average Score: {rag_results['average_score']:.2%}\")\n",
    "print(f\"Total Alerts Evaluated: {len(rag_results['eval_output_items'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58efda71",
   "metadata": {},
   "source": [
    "Up to this point, we have shown how to add models and tunable LLM parameters to the `SearchSpace`. We have demonstrated this using `sampler: grid`, which uses Optuna's grid search methods to create a deterministic search space for all of the unique combinations for all `optimizable_params` in the configuration. If range of search parameters is large, and a grid search produces too many unique combinations, users may optionally specify `sampler: bayesian` in their configuration, and use Optuna's `TPESampler` (univariate) and genetic algorithm (multivariable) samplers to use non-deterministic search methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6eb63",
   "metadata": {},
   "source": [
    "<a id=\"model-and-prompt-tuning\"></a>\n",
    "# 3.0) Concurrent Model Parameter and Prompt Tuning\n",
    "\n",
    "NAT uses a Genetic Algorithm (GA) to automatically optimize prompts through evolutionary search. This is a sophisticated approach that treats prompts as \"individuals\" in a population that evolves over multiple generations to find better-performing variations. The genetic algorithm is inspired by natural evolution and uses LLMs themselves to intelligently mutate and recombine prompts. Instead of random mutations like traditional GAs, NAT leverages the reasoning capabilities of LLMs to make informed changes to prompts.\n",
    "\n",
    "*Note: The genetic algorithm for prompt optimization is configured through several parameters:*\n",
    "- *`prompt.enabled`: Enable GA-based prompt optimization (default: `false`)*\n",
    "- *`prompt.ga_population_size`: Population size - larger populations increase diversity but cost more per generation (default: `10`)*\n",
    "- *`prompt.ga_generations`: Number of generations to evolve prompts (default: `5`)*\n",
    "- *`prompt.ga_offspring_size`: Number of offspring per generation - if `null`, defaults to `ga_population_size - ga_elitism`*\n",
    "- *`prompt.ga_crossover_rate`: Probability of recombination between two parents for each prompt parameter (default: `0.7`)*\n",
    "- *`prompt.ga_mutation_rate`: Probability of mutating a child's prompt parameter using the LLM optimizer (default: `0.1`)*\n",
    "- *`prompt.ga_elitism`: Number of elite individuals copied unchanged to the next generation (default: `1`)*\n",
    "- *`prompt.ga_selection_method`: Parent selection scheme - `tournament` (default) or `roulette`*\n",
    "- *`prompt.ga_tournament_size`: Tournament size when using tournament selection (default: `3`)*\n",
    "- *`prompt.ga_parallel_evaluations`: Maximum number of concurrent evaluations (default: `8`)*\n",
    "- *`prompt.ga_diversity_lambda`: Diversity penalty strength to discourage duplicate prompt sets - `0.0` disables it (default: `0.0`)- *`prompt.prompt_population_init_function`: Function name used to mutate base prompts to seed the initial population and perform tations. NAT includes a built-in `prompt_init` Function you can use.*\n",
    "- *`prompt.prompt_recombination_function`: Optional function name used to recombine two parent prompts into a child prompt. NAT cludes a built-in `prompt_recombiner` Function you can use.*\n",
    "\n",
    "** For more information see the [Optimizer documentation](../../docs/source/reference/optimizer.md) or go to your working branch on [Github - dev](https://github.com/NVIDIA/NeMo-Agent-Toolkit/blob/develop/docs/source/reference/optimizer.md).**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbcac0",
   "metadata": {},
   "source": [
    "<a id=\"all-tuning-config\"></a>\n",
    "## 3.1) Optimizer configuration for all parameters (models, hyperparameters, and prompts)\n",
    "\n",
    "For this experiment we will create a new configuration at `tmp_workflow/configs/alert_triage_all_params_selection.yml`, for which we will configure an optimizer run to find the best model (backbone LLM only), hyperparameters (temperature only), and prompts. We can use our existing Alert Triage Agent here, with a modified config. Let's create a new config called `./tmp_workflow/configs/alert_triage_config_all_params_selection.yml` to manage this workflow for us.\n",
    "\n",
    "First we will copy the same base configuration as the last example - with updated output paths for this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./tmp_workflow/configs/alert_triage_config_all_params_selection.yml\n",
    "# path-check-skip-begin\n",
    "functions:\n",
    "  hardware_check:\n",
    "    _type: hardware_check\n",
    "    llm_name: tool_reasoning_llm\n",
    "    offline_mode: true\n",
    "  host_performance_check:\n",
    "    _type: host_performance_check\n",
    "    llm_name: tool_reasoning_llm\n",
    "    offline_mode: true\n",
    "  monitoring_process_check:\n",
    "    _type: monitoring_process_check\n",
    "    llm_name: tool_reasoning_llm\n",
    "    offline_mode: true\n",
    "  network_connectivity_check:\n",
    "    _type: network_connectivity_check\n",
    "    llm_name: tool_reasoning_llm\n",
    "    offline_mode: true\n",
    "  telemetry_metrics_host_heartbeat_check:\n",
    "    _type: telemetry_metrics_host_heartbeat_check\n",
    "    llm_name: tool_reasoning_llm\n",
    "    offline_mode: true\n",
    "  telemetry_metrics_host_performance_check:\n",
    "    _type: telemetry_metrics_host_performance_check\n",
    "    llm_name: tool_reasoning_llm\n",
    "    offline_mode: true\n",
    "  telemetry_metrics_analysis_agent:\n",
    "    _type: telemetry_metrics_analysis_agent\n",
    "    tool_names:\n",
    "      - telemetry_metrics_host_heartbeat_check\n",
    "      - telemetry_metrics_host_performance_check\n",
    "    llm_name: agent_llm\n",
    "  maintenance_check:\n",
    "    _type: maintenance_check\n",
    "    llm_name: agent_llm\n",
    "    static_data_path: PLACEHOLDER_maintenance_static_dataset.csv\n",
    "  categorizer:\n",
    "    _type: categorizer\n",
    "    llm_name: agent_llm\n",
    "\n",
    "workflow:\n",
    "  _type: alert_triage_agent\n",
    "  tool_names:\n",
    "    - hardware_check\n",
    "    - host_performance_check\n",
    "    - monitoring_process_check\n",
    "    - network_connectivity_check\n",
    "    - telemetry_metrics_analysis_agent\n",
    "  llm_name: agent_llm\n",
    "  offline_mode: true\n",
    "  offline_data_path: PLACEHOLDER_offline_data.csv\n",
    "  benign_fallback_data_path: PLACEHOLDER_benign_fallback_offline_data.json\n",
    "\n",
    "llms:\n",
    "  agent_llm:\n",
    "    _type: nim\n",
    "    model_name: meta/llama-3.1-8b-instruct\n",
    "    temperature: 0.0\n",
    "    max_tokens: 2048\n",
    "    optimizable_params:\n",
    "      - model_name\n",
    "      - temperature\n",
    "    search_space:\n",
    "      model_name:\n",
    "        values:\n",
    "          - meta/llama-3.1-8b-instruct\n",
    "          - meta/llama-3.1-70b-instruct\n",
    "          # - meta/llama-3.1-405b-instruct\n",
    "          # - meta/llama-3.3-3b-instruct\n",
    "          # - meta/llama-3.3-70b-instruct\n",
    "          # - meta/llama-4-scout-17b-16e-instruct\n",
    "          # - openai/gpt-oss-20b\n",
    "          # - openai/gpt-oss-120b\n",
    "          # - ibm/granite-3.3-8b-instruct\n",
    "          # - mistralai/mistral-small-3.1-24b-instruct-2503\n",
    "          # - mistralai/mistral-medium-3-instruct\n",
    "    temperature:\n",
    "      values:\n",
    "        - 0.0\n",
    "        - 0.5\n",
    "  tool_reasoning_llm:\n",
    "    _type: nim\n",
    "    model_name: meta/llama-3.1-70b-instruct\n",
    "    temperature: 0.2\n",
    "    max_tokens: 2048\n",
    "  nim_rag_eval_llm:\n",
    "    _type: nim\n",
    "    model_name: meta/llama-3.1-70b-instruct\n",
    "    max_tokens: 8\n",
    "\n",
    "eval:\n",
    "  general:\n",
    "    output_dir: ./tmp_workflow/alert_triage_all_params_selection_output/\n",
    "    dataset:\n",
    "      _type: json\n",
    "      file_path: PLACEHOLDER_offline_data.json\n",
    "  evaluators:\n",
    "    classification_accuracy:\n",
    "      _type: classification_accuracy\n",
    "    rag_accuracy:\n",
    "      _type: ragas\n",
    "      metric: AnswerAccuracy\n",
    "      llm_name: nim_rag_eval_llm\n",
    "  profiler:\n",
    "    token_uniqueness_forecast: true\n",
    "    workflow_runtime_forecast: true\n",
    "    compute_llm_metrics: true\n",
    "    csv_exclude_io_text: true\n",
    "    prompt_caching_prefixes:\n",
    "      enable: true\n",
    "      min_frequency: 0.1\n",
    "    bottleneck_analysis:\n",
    "      enable_nested_stack: true\n",
    "    concurrency_spike_analysis:\n",
    "      enable: true\n",
    "      spike_threshold: 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1eb804",
   "metadata": {},
   "source": [
    "Then we will add in updated optimizer configuration code that allows the system prompts to be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4646a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a ./tmp_workflow/configs/alert_triage_config_all_params_selection.yml\n",
    "optimizer:\n",
    "  output_path: ./tmp_workflow/alert_triage_all_params_selection_output/optimizer/\n",
    "  reps_per_param_set: 1\n",
    "  eval_metrics:\n",
    "    classification_accuracy:\n",
    "      evaluator_name: classification_accuracy\n",
    "      direction: maximize\n",
    "  numeric:\n",
    "    enabled: true\n",
    "    sampler: grid\n",
    "  prompt:\n",
    "    enabled: false\n",
    "# path-check-skip-end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c14f8",
   "metadata": {},
   "source": [
    "Again, we will replace the placeholder paths for the output artifacts based on our earlier NAT source code pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3316dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace placeholder paths with actual package data paths\n",
    "import importlib.resources\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "\n",
    "# Get the package data path\n",
    "package_data = importlib.resources.files('nat_alert_triage_agent').joinpath('data')\n",
    "\n",
    "# Read the YAML file\n",
    "config_path = Path('./tmp_workflow/configs/alert_triage_config_all_params_selection.yml')\n",
    "with open(config_path, 'r') as f:\n",
    "    config_content = f.read()\n",
    "\n",
    "# Replace placeholders with actual paths\n",
    "replacements = {\n",
    "    'PLACEHOLDER_maintenance_static_dataset.csv': str(package_data / 'maintenance_static_dataset.csv'),\n",
    "    'PLACEHOLDER_offline_data.csv': str(package_data / 'offline_data.csv'),\n",
    "    'PLACEHOLDER_benign_fallback_offline_data.json': str(package_data / 'benign_fallback_offline_data.json'),\n",
    "    'PLACEHOLDER_offline_data.json': str(package_data / 'offline_data.json')\n",
    "}\n",
    "\n",
    "for placeholder, actual_path in replacements.items():\n",
    "    config_content = config_content.replace(placeholder, actual_path)\n",
    "\n",
    "# Write back to file\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(f\"✓ Config written with data paths from: {package_data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceceea3",
   "metadata": {},
   "source": [
    "<a id=\"all-tuning-initial-eval\"></a>\n",
    "## 3.2) Evaluate the agent\n",
    "\n",
    "As we've already tested this agent in Section 2.3, we will go right ahead to an initial evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nat eval --config_file ./tmp_workflow/configs/alert_triage_config_all_params_selection.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7489c",
   "metadata": {},
   "source": [
    "Then let's analyze the results of the untuned agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b58195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display classification accuracy results\n",
    "# path-check-skip-next-line\n",
    "with open('./tmp_workflow/alert_triage_all_params_selection_output/classification_accuracy_output.json') as f:\n",
    "    classification_results = json.load(f)\n",
    "\n",
    "print(\"Classification Accuracy Results:\")\n",
    "print(f\"Average Score: {classification_results['average_score']:.2%}\")\n",
    "print(\"\\nPer-Alert Results:\")\n",
    "for item in classification_results['eval_output_items']:\n",
    "    print(f\"  Alert {item['id']}: Score={item['score']:.2f} - {item['reasoning']}\")\n",
    "\n",
    "# Load and display RAG accuracy results\n",
    "# path-check-skip-next-line\n",
    "with open('./tmp_workflow/alert_triage_all_params_selection_output/rag_accuracy_output.json') as f:\n",
    "    rag_results = json.load(f)\n",
    "\n",
    "print(\"\\n\\nRAG Accuracy Results:\")\n",
    "print(f\"Average Score: {rag_results['average_score']:.2%}\")\n",
    "print(f\"Total Alerts Evaluated: {len(rag_results['eval_output_items'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5813af73",
   "metadata": {},
   "source": [
    "<a id=\"all-tuning-optimize\"></a>\n",
    "## 3.3) Optimize the agent\n",
    "\n",
    "Now let's re-run the optmize, but this time we will have model, parameter, and prompt tuning all enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754bd302",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nat optimize --config_file tmp_workflow/configs/alert_triage_config_all_params_selection.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b51cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the optimizer results\n",
    "trials_df_path = Path(\"tmp_workflow/alert_triage_all_params_selection_output/optimizer/trials_dataframe_params.csv\")\n",
    "\n",
    "if trials_df_path.exists():\n",
    "    trials_df = pd.read_csv(trials_df_path)\n",
    "\n",
    "    print(\"Grid Search Optimization Results\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nTrials Summary:\")\n",
    "    print(trials_df.to_string(index=False))\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"\\nModel Performance Statistics (Mean across repetitions):\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Group by model name to calculate statistics across repetitions\n",
    "    for model_name in trials_df['params_llms.agent_llm.model_name'].unique():\n",
    "        model_trials = trials_df[trials_df['params_llms.agent_llm.model_name'] == model_name]\n",
    "\n",
    "        print(f\"\\n{model_name}:\")\n",
    "\n",
    "        # Parse rep_scores to extract individual repetition metrics\n",
    "        if 'rep_scores' in model_trials.columns:\n",
    "            all_classification_accuracies = []\n",
    "            all_rag_accuracies = []\n",
    "\n",
    "            for rep_scores_str in model_trials['rep_scores']:\n",
    "                rep_scores = ast.literal_eval(rep_scores_str)\n",
    "                for score_set in rep_scores:\n",
    "                    # score_set format: [classification_accuracy, rag_accuracy]\n",
    "                    all_classification_accuracies.append(score_set[0])\n",
    "                    all_rag_accuracies.append(score_set[1])\n",
    "\n",
    "            # Calculate mean and standard deviation\n",
    "            def calculate_stats(values):\n",
    "                mean = np.mean(values)\n",
    "                std = np.std(values)\n",
    "                ci_lower = np.percentile(values, 2.5)\n",
    "                ci_upper = np.percentile(values, 97.5)\n",
    "                return mean, std, ci_lower, ci_upper\n",
    "\n",
    "            class_acc_mean, class_acc_std, class_acc_ci_lower, class_acc_ci_upper = \\\n",
    "                calculate_stats(all_classification_accuracies)\n",
    "            rag_acc_mean, rag_acc_std, rag_acc_ci_lower, rag_acc_ci_upper = calculate_stats(all_rag_accuracies)\n",
    "\n",
    "            print(\"  Classification Accuracy:\")\n",
    "            print(f\"    Mean: {class_acc_mean:.3f} (±{class_acc_std:.3f})\")\n",
    "            print(f\"    95% CI: [{class_acc_ci_lower:.3f}, {class_acc_ci_upper:.3f}]\")\n",
    "\n",
    "            print(\"  RAG Accuracy:\")\n",
    "            print(f\"    Mean: {rag_acc_mean:.3f} (±{rag_acc_std:.3f})\")\n",
    "            print(f\"    95% CI: [{rag_acc_ci_lower:.3f}, {rag_acc_ci_upper:.3f}]\")\n",
    "        else:\n",
    "            # Fallback to aggregated values if rep_scores not available\n",
    "            # values_0 = classification_accuracy, values_1 = rag_accuracy\n",
    "            class_acc_mean = np.mean(model_trials['values_0'])\n",
    "            rag_acc_mean = np.mean(model_trials['values_1'])\n",
    "\n",
    "            print(f\"  Classification Accuracy (mean): {class_acc_mean:.3f}\")\n",
    "            print(f\"  RAG Accuracy (mean): {rag_acc_mean:.3f}\")\n",
    "            print(\"  Note: 95% CI not available without rep_scores data\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"\\nBest Configuration (by aggregated classification accuracy across all repetitions):\")\n",
    "    # Find the trial with best aggregated classification accuracy\n",
    "    best_trial = trials_df.loc[trials_df['values_0'].idxmax()]\n",
    "    print(f\"Model: {best_trial['params_llms.agent_llm.model_name']}\")\n",
    "    print(f\"Aggregated Classification Accuracy Score: {best_trial['values_0']}\")\n",
    "    print(f\"Aggregated RAG Accuracy: {best_trial['values_1']}\")\n",
    "else:\n",
    "    print(f\"Optimizer results not found at {trials_df_path}\")\n",
    "    print(\"Please run the optimizer first (cell 55)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69001d0",
   "metadata": {},
   "source": [
    "<a id=\"eval-triage-agent2\"></a>\n",
    "## 3.4) Re-evaluate the optimized tool-calling agent\n",
    "\n",
    "After completing the `nat optimize` run above, a new file with the optimal parameters from the search have been serialized and saved to `'./tmp_workflow/alert_triage_all_params_selection_output/optimizer/optimized_config.yml`. Let's re-run those optimized parameters back through `nat eval` and compare the performance.\n",
    "\n",
    "<div style=\"color: red; font-style: italic;\">\n",
    "<strong>Note:</strong> Performance of the optimized model may vary due to size of prior search space and number of evaluation trials.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a94fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path-check-skip-next-line\n",
    "!nat eval --config_file ./tmp_workflow/alert_triage_all_params_selection_output/optimizer/optimized_config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152cdd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load and display classification accuracy results\n",
    "# path-check-skip-next-line\n",
    "with open('./tmp_workflow/alert_triage_all_params_selection_output/classification_accuracy_output.json') as f:\n",
    "    classification_results = json.load(f)\n",
    "\n",
    "print(\"Classification Accuracy Results:\")\n",
    "print(f\"Average Score: {classification_results['average_score']:.2%}\")\n",
    "print(\"\\nPer-Alert Results:\")\n",
    "for item in classification_results['eval_output_items']:\n",
    "    print(f\"  Alert {item['id']}: Score={item['score']:.2f} - {item['reasoning']}\")\n",
    "\n",
    "# Load and display RAG accuracy results\n",
    "# path-check-skip-next-line\n",
    "with open('./tmp_workflow/alert_triage_all_params_selection_output/rag_accuracy_output.json') as f:\n",
    "    rag_results = json.load(f)\n",
    "\n",
    "print(\"\\n\\nRAG Accuracy Results:\")\n",
    "print(f\"Average Score: {rag_results['average_score']:.2%}\")\n",
    "print(f\"Total Alerts Evaluated: {len(rag_results['eval_output_items'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4682debd",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20f6d61",
   "metadata": {},
   "source": [
    "<a id=\"next-steps\"></a>\n",
    "# 4.0) Next steps\n",
    "\n",
    "Continue learning how to fully utilize the NVIDIA NeMo Agent toolkit by exploring the other documentation and advanced agents in the `examples` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unew_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

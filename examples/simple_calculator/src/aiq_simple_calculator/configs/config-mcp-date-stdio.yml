# SPDX-FileCopyrightText: Copyright (c) 2024-2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This config file shows how to use the MCP server to get the current date and time.
# Here the workflow acts as a MCP client and connects to the MCP server running
# on the specified URL (defaults to `http://localhost:8080/sse`).

general:
  use_uvloop: true

functions:
  mcp_server_aiq_math:
    _type: mcp_client
    server:
      transport: sse
      url: "http://localhost:9901/sse"
    # load all tools and use the descriptions from the server

  mcp_server_time_stdio:
    _type: mcp_client
    server:
      transport: stdio
      command: "python"
      args: ["-m", "mcp_server_time", "--local-timezone=America/Los_Angeles"]
    tool_filter:
      # load 1 of 2 tools and override the description
      get_current_time:
        "alias": "mcp_time_tool"
        "description": "Returns the current date and time from the MCP server"

  mcp_server_github:
    _type: mcp_client
    server:
      transport: stdio
      command: "docker"
      args: ["run", "-i", "--rm", "-e", "GITHUB_PERSONAL_ACCESS_TOKEN", "ghcr.io/github/github-mcp-server"]
      env:
        GITHUB_PERSONAL_ACCESS_TOKEN: "${GITHUB_PERSONAL_ACCESS_TOKEN}"
    tool_filter:
      # load 2 of 40 tools and use the descriptions from the server
      - list_issues
      - get_issue


llms:
  nim_llm:
    _type: nim
    model_name: meta/llama-3.1-70b-instruct
    temperature: 0.0
    max_tokens: 1024
  openai_llm:
    _type: openai
    model_name: gpt-3.5-turbo
    max_tokens: 2000

workflow:
  _type: react_agent
  tool_names:
    - calculator_multiply
    - calculator_inequality
    - calculator_divide
    - calculator_subtract
    - mcp_time_tool

  llm_name: nim_llm
  verbose: true
  retry_parsing_errors: true
  max_retries: 3
